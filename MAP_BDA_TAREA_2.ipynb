{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evRF3jlC8n6V"
   },
   "source": [
    "# IMPORTACIÓN DE LIBRERÍAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1993,
     "status": "ok",
     "timestamp": 1734609400589,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "IOKWxYw58GlE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FAiPMl-8uKh"
   },
   "source": [
    "# IMPORTACIÓN DEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 912,
     "status": "ok",
     "timestamp": 1734609401498,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "1gpkuQau7tcU",
    "outputId": "f6c45f14-1afc-464d-ffe9-aaaafe263c95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1352k  100 1352k    0     0  1625k      0 --:--:-- --:--:-- --:--:-- 9593k\n"
     ]
    }
   ],
   "source": [
    "!curl -L -o telefonos-2024.zip\\\n",
    "https://www.kaggle.com/api/v1/datasets/download/jakubkhalponiak/phones-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1734609401883,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "RiC6lkiw77o9",
    "outputId": "9b3d4736-5c37-440a-c627-a9bbd9656b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  telefonos-2024.zip\n",
      "  inflating: data.json               \n",
      "  inflating: processed_data2.csv     \n"
     ]
    }
   ],
   "source": [
    "!unzip telefonos-2024.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1061,
     "status": "ok",
     "timestamp": 1734609402942,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "bX4UcL0a8KF3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_data2.csv')\n",
    "df_J = pd.read_json(('data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1734609402942,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "XQhr9aWbN6Si",
    "outputId": "dc5fee4d-4bf5-45e9-c909-d5256ecee466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone_brand,phone_model,store,price_usd,storage,ram,launch_date,dimensions,weight,display_type,display_size,display_resolution,os,nfc,usb,battery,features_sensors,colors,video,chipset,cpu,gpu,year,foldable,ppi_density,quantile_10,quantile_50,quantile_90,price_range,os_type,os_version,battery_size,colors_available,chip_company,cpu_core,gpu_company,fingerprint,video_resolution\n",
      "apple,Apple iPhone 16 Pro,Amazon DE,1357.55,256,8,2024-09-20,149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in),199.0,\"LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolby Vision, 1000 nits (typ), 2000 nits (HBM)\",6.3,1206 x 2622,iOS 18,1,\"USB Type-C 3.2 Gen 2, DisplayPort\",3582,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black Titanium, White Titanium, Natural Titanium, Desert Titanium\",\"4K@24/25/30/60/100/120fps, 1080p@25/30/60/120/240fps, 10-bit HDR, Dolby Vision HDR (up to 60fps), ProRes, 3D (spatial) video/audio, stereo sound rec.\",Apple A18 Pro (3 nm),Hexa-core (2x4.05 GHz + 4x2.42 GHz),Apple GPU (6-core graphics),2024-01-01,0,460,161.707,550.45,1375.35,medium price,iOS,18,Medium,4,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 16 Pro,Amazon DE,1492.55,512,8,2024-09-20,149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in),199.0,\"LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolby Vision, 1000 nits (typ), 2000 nits (HBM)\",6.3,1206 x 2622,iOS 18,1,\"USB Type-C 3.2 Gen 2, DisplayPort\",3582,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black Titanium, White Titanium, Natural Titanium, Desert Titanium\",\"4K@24/25/30/60/100/120fps, 1080p@25/30/60/120/240fps, 10-bit HDR, Dolby Vision HDR (up to 60fps), ProRes, 3D (spatial) video/audio, stereo sound rec.\",Apple A18 Pro (3 nm),Hexa-core (2x4.05 GHz + 4x2.42 GHz),Apple GPU (6-core graphics),2024-01-01,0,460,161.707,550.45,1375.35,high price,iOS,18,Medium,4,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 16 Pro,Amazon DE,1705.32,1000,8,2024-09-20,149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in),199.0,\"LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolby Vision, 1000 nits (typ), 2000 nits (HBM)\",6.3,1206 x 2622,iOS 18,1,\"USB Type-C 3.2 Gen 2, DisplayPort\",3582,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black Titanium, White Titanium, Natural Titanium, Desert Titanium\",\"4K@24/25/30/60/100/120fps, 1080p@25/30/60/120/240fps, 10-bit HDR, Dolby Vision HDR (up to 60fps), ProRes, 3D (spatial) video/audio, stereo sound rec.\",Apple A18 Pro (3 nm),Hexa-core (2x4.05 GHz + 4x2.42 GHz),Apple GPU (6-core graphics),2024-01-01,0,460,161.707,550.45,1375.35,high price,iOS,18,Medium,4,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 16 Pro Max,Amazon DE,1564.92,512,8,2024-09-20,163 x 77.6 x 8.3 mm (6.42 x 3.06 x 0.33 in),227.0,\"LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolby Vision, 1000 nits (typ), 2000 nits (HBM)\",6.9,1320 x 2868,iOS 18,1,\"USB Type-C 3.2 Gen 2, DisplayPort\",4685,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black Titanium, White Titanium, Natural Titanium, Desert Titanium\",\"4K@24/25/30/60/100/120fps, 1080p@25/30/60/120/240fps, 10-bit HDR, Dolby Vision HDR (up to 60fps), ProRes, 3D (spatial) video/audio, stereo sound rec.\",Apple A18 Pro (3 nm),Hexa-core (2x4.05 GHz + 4x2.42 GHz),Apple GPU (6-core graphics),2024-01-01,0,460,161.707,550.45,1375.35,high price,iOS,18,Large,4,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 12 mini,Amazon DE,247.32,128,4,2020-11-13,131.5 x 64.2 x 7.4 mm (5.18 x 2.53 x 0.29 in),135.0,\"Super Retina XDR OLED, HDR10, Dolby Vision, 625 nits (HBM), 1200 nits (peak)\",5.4,1080 x 2340,\"iOS 14.1, upgradable to iOS 18\",1,\"Lightning, USB 2.0\",2227,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black, White, Red, Green, Blue, Purple\",\"4K@24/30/60fps, 1080p@30/60/120/240fps, HDR, Dolby Vision HDR (up to 30fps), stereo sound rec.\",Apple A14 Bionic (5 nm),Hexa-core (2x3.1 GHz Firestorm + 4x1.8 GHz Icestorm),Apple GPU (4-core graphics),2020-01-01,0,476,100.8,196.81,491.512,medium price,iOS,14.1,Small,6,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 12 mini,Amazon DE,319.68,256,4,2020-11-13,131.5 x 64.2 x 7.4 mm (5.18 x 2.53 x 0.29 in),135.0,\"Super Retina XDR OLED, HDR10, Dolby Vision, 625 nits (HBM), 1200 nits (peak)\",5.4,1080 x 2340,\"iOS 14.1, upgradable to iOS 18\",1,\"Lightning, USB 2.0\",2227,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black, White, Red, Green, Blue, Purple\",\"4K@24/30/60fps, 1080p@30/60/120/240fps, HDR, Dolby Vision HDR (up to 30fps), stereo sound rec.\",Apple A14 Bionic (5 nm),Hexa-core (2x3.1 GHz Firestorm + 4x1.8 GHz Icestorm),Apple GPU (4-core graphics),2020-01-01,0,476,100.8,196.81,491.512,medium price,iOS,14.1,Small,6,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 13 mini,Amazon DE,427.14,256,4,2021-09-24,131.5 x 64.2 x 7.7 mm (5.18 x 2.53 x 0.30 in),141.0,\"Super Retina XDR OLED, HDR10, Dolby Vision, 800 nits (HBM), 1200 nits (peak)\",5.4,1080 x 2340,\"iOS 15, upgradable to iOS 18\",1,\"Lightning, USB 2.0\",2438,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Starlight, Midnight, Blue, Pink, Red, Green\",\"4K@24/30/60fps, 1080p@30/60/120/240fps, HDR, Dolby Vision HDR (up to 60fps), stereo sound rec.\",Apple A15 Bionic (5 nm),Hexa-core (2x3.23 GHz Avalanche + 4x1.82 GHz Blizzard),Apple GPU (4-core graphics),2021-01-01,0,476,127.03,249.99,581.99,medium price,iOS,15,Small,6,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone 13 mini,Amazon DE,467.64,512,4,2021-09-24,131.5 x 64.2 x 7.7 mm (5.18 x 2.53 x 0.30 in),141.0,\"Super Retina XDR OLED, HDR10, Dolby Vision, 800 nits (HBM), 1200 nits (peak)\",5.4,1080 x 2340,\"iOS 15, upgradable to iOS 18\",1,\"Lightning, USB 2.0\",2438,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Starlight, Midnight, Blue, Pink, Red, Green\",\"4K@24/30/60fps, 1080p@30/60/120/240fps, HDR, Dolby Vision HDR (up to 60fps), stereo sound rec.\",Apple A15 Bionic (5 nm),Hexa-core (2x3.23 GHz Avalanche + 4x1.82 GHz Blizzard),Apple GPU (4-core graphics),2021-01-01,0,476,127.03,249.99,581.99,medium price,iOS,15,Small,6,Apple,Hexa-core,Apple,Face,4K\n",
      "apple,Apple iPhone XR,Amazon DE,213.85,128,3,2018-10-26,150.9 x 75.7 x 8.3 mm (5.94 x 2.98 x 0.33 in),194.0,\"Liquid Retina IPS LCD, 625 nits (HBM)\",6.1,828 x 1792,\"iOS 12, upgradable to iOS 18\",1,\"Lightning, USB 2.0\",2942,\"Face ID, accelerometer, gyro, proximity, compass, barometer\",\"Black, Red, Yellow, Blue, Coral, White\",\"4K@24/30/60fps, 1080p@30/60/120/240fps, HDR, stereo sound rec.\",Apple A12 Bionic (7 nm),Hexa-core (2x2.5 GHz Vortex + 4x1.6 GHz Tempest),Apple GPU (4-core graphics),2018-01-01,0,326,140.912,213.85,310.648,medium price,iOS,12,Small,6,Apple,Hexa-core,Apple,Face,4K\n"
     ]
    }
   ],
   "source": [
    "!head processed_data2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1734609403394,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "hXN1S4NlOB2B",
    "outputId": "271a110c-4ec8-4276-e4d3-257ea6bd7f20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "{\"phone_brand\": \"itel\", \"phone_model\": \"itel Smart Watch 1\", \"price\": null, \"specs\": {\"Network\": {\"2G bands\": \" N/A\", \"3G bands\": \" N/A\", \"4G bands\": \" N/A\", \"Speed\": \"No\", \"GPRS\": \"No\", \"EDGE\": \"No\"}, \"Launch\": {\"Announced\": \"2022\", \"Status\": \"Available. Released 2022\"}, \"Body\": {\"Dimensions\": \"-\", \"Weight\": \"-\", \"Build\": \"Plastic back, plastic frame\", \"SIM\": \"No\"}, \"Display\": {\"Type\": \"IPS LCD\", \"Size\": \"1.72 inches\", \"Resolution\": \"240 x 283 pixels (~216 ppi density)\"}, \"Platform\": {\"OS\": \"Proprietary OS\"}, \"Memory\": {\"Card slot\": \"No\", \"Internal\": \"Unspecified storage\"}, \"Sound\": {\"Loudspeaker\": \"Yes\", \"3.5mm jack\": \"No\"}, \"Comms\": {\"WLAN\": \"No\", \"Bluetooth\": \"5.0, A2DP, LE\", \"Positioning\": \"No\", \"NFC\": \"No\", \"Radio\": \"No\", \"USB\": \"No\"}, \"Features\": {\"Sensors\": \"Accelerometer, heart rate, SpO2\"}, \"Battery\": {\"Type\": \"200 mAh, non-removable\"}, \"Misc\": {\"Colors\": \"Black\"}}},\n",
      "{\"phone_brand\": \"oukitel\", \"phone_model\": \"Oukitel WP19\", \"price\": \"About 380 EUR\", \"specs\": {\"Network\": {\"2G bands\": \"GSM 850 / 900 / 1800 / 1900 - SIM 1 & SIM 2\", \"3G bands\": \"HSDPA 850 / 900 / 1700(AWS) / 1900 / 2100 \", \"4G bands\": \" LTE\", \"Speed\": \"HSPA, LTE\"}, \"Launch\": {\"Announced\": \"2022, June\", \"Status\": \"Available. Released 2022, July\"}, \"Body\": {\"Dimensions\": \"-\", \"Weight\": \"-\", \"SIM\": \"Dual SIM (Nano-SIM, dual stand-by)\"}, \"Display\": {\"Type\": \"IPS LCD, 90Hz\", \"Size\": \"6.78 inches, 109.2 cm\", \"Resolution\": \"1080 x 2460 pixels (~396 ppi density)\"}, \"Platform\": {\"OS\": \"Android 12\", \"Chipset\": \"Mediatek MT6785V/CD Helio G95 (12 nm)\", \"CPU\": \"Octa-core (2x2.05 GHz Cortex-A76 & 6x2.0 GHz Cortex-A55)\", \"GPU\": \"Mali-G76 MC4\"}, \"Memory\": {\"Card slot\": \"microSDXC (dedicated slot)\", \"Internal\": \"256GB 8GB RAM\"}, \"Main Camera\": {\"Triple\": \"64 MP, f/1.8, (wide), PDAF\", \"Features\": \"LED flash, panorama\", \"Video\": \"4K@30fps, 1080p@30fps\"}, \"Selfie camera\": {\"Single\": \"16 MP\", \"Video\": \"Yes\"}, \"Sound\": {\"Loudspeaker\": \"Yes\", \"3.5mm jack\": \"Unspecified\"}, \"Comms\": {\"WLAN\": \"Yes\", \"Bluetooth\": \"Yes\", \"Positioning\": \"GPS, GLONASS, GALILEO, BDS\", \"NFC\": \"Yes\", \"Radio\": \"Unspecified\", \"USB\": \"USB Type-C 2.0, OTG\"}, \"Features\": {\"Sensors\": \"Unspecified\"}, \"Battery\": {\"Type\": \"Li-Po 21000 mAh, non-removable\", \"Charging\": \"33W wired\"}, \"Misc\": {\"Colors\": \"Blue, Camo, Camouflage\", \"Price\": \"About 380 EUR\"}}},\n",
      "{\"phone_brand\": \"cubot\", \"phone_model\": \"Cubot Smart Watch\", \"price\": null, \"specs\": {\"Network\": {\"2G bands\": \" N/A\", \"3G bands\": \" N/A\", \"4G bands\": \" N/A\", \"Speed\": \"No\", \"GPRS\": \"No\", \"EDGE\": \"No\"}, \"Launch\": {\"Announced\": \"2020\", \"Status\": \"Available. Released 2020\"}, \"Body\": {\"Dimensions\": \"41.6 x 41.6 x 11.6 mm (1.64 x 1.64 x 0.46 in)\", \"Weight\": \"-\", \"SIM\": \"No\"}, \"Display\": {\"Type\": \"TFT LCD\", \"Size\": \"1.3 inches\", \"Resolution\": \"240 x 240 pixels (~261 ppi density)\", \"Protection\": \"Scratch-resistant glass\"}, \"Platform\": {\"OS\": \"Proprietary OS\"}, \"Memory\": {\"Card slot\": \"No\"}, \"Sound\": {\"Loudspeaker\": \"No\", \"3.5mm jack\": \"No\"}, \"Comms\": {\"WLAN\": \"No\", \"Bluetooth\": \"5.0, A2DP, LE\", \"Positioning\": \"No\", \"NFC\": \"No\", \"Radio\": \"No\", \"USB\": \"No\"}, \"Features\": {\"Sensors\": \"Accelerometer, gyro, heart rate\"}, \"Battery\": {\"Type\": \"210 mAh, non-removable\"}, \"Misc\": {\"Colors\": \"Black, Pink\"}}},\n",
      "{\"phone_brand\": \"cubot\", \"phone_model\": \"Cubot ID206\", \"price\": null, \"specs\": {\"Network\": {\"2G bands\": \" N/A\", \"3G bands\": \" N/A\", \"4G bands\": \" N/A\", \"Speed\": \"No\", \"GPRS\": \"No\", \"EDGE\": \"No\"}, \"Launch\": {\"Announced\": \"2020\", \"Status\": \"Available. Released 2020\"}, \"Body\": {\"Dimensions\": \"40 x 40 x 12 mm (1.57 x 1.57 x 0.47 in)\", \"Weight\": \"-\", \"SIM\": \"No\"}, \"Display\": {\"Type\": \"TFT LCD\", \"Size\": \"1.7 inches\", \"Resolution\": \"240 x 280 pixels (~217 ppi density)\", \"Protection\": \"Scratch-resistant glass\"}, \"Platform\": {\"OS\": \"Proprietary OS\"}, \"Memory\": {\"Card slot\": \"No\"}, \"Sound\": {\"Loudspeaker\": \"No\", \"3.5mm jack\": \"No\"}, \"Comms\": {\"WLAN\": \"No\", \"Bluetooth\": \"5.0, A2DP, LE\", \"Positioning\": \"No\", \"NFC\": \"No\", \"Radio\": \"No\", \"USB\": \"No\"}, \"Features\": {\"Sensors\": \"Accelerometer, gyro, heart rate, SpO2\"}, \"Battery\": {\"Type\": \"300 mAh, non-removable\"}, \"Misc\": {\"Colors\": \"Black, Pink\"}}},\n",
      "{\"phone_brand\": \"tcl\", \"phone_model\": \"TCL Plex\", \"price\": \"About 330 EUR\", \"specs\": {\"Network\": {\"2G bands\": \"GSM 850 / 900 / 1800 / 1900 - SIM 1 & SIM 2 (Dual SIM model only)\", \"3G bands\": \"HSDPA 850 / 900 / 1900 / 2100 \", \"4G bands\": \"1, 3, 5, 7, 8, 20, 28, 38, 40\", \"Speed\": \"HSPA 42.2/5.76 Mbps, LTE (2CA) Cat6 400/75 Mbps\"}, \"Launch\": {\"Announced\": \"2019, September\", \"Status\": \"Available. Released 2019, October\"}, \"Body\": {\"Dimensions\": \"162.2 x 76.6 x 8 mm (6.39 x 3.02 x 0.31 in)\", \"Weight\": \"192 g (6.77 oz)\", \"Build\": \"Glass front, glass back, aluminum frame\", \"SIM\": \"Single SIM (Nano-SIM) or Hybrid Dual SIM (Nano-SIM, dual stand-by)\"}, \"Display\": {\"Type\": \"IPS LCD\", \"Size\": \"6.53 inches, 104.7 cm\", \"Resolution\": \"1080 x 2340 pixels, 19.5:9 ratio (~395 ppi density)\"}, \"Platform\": {\"OS\": \"Android 9.0 (Pie), upgradable to Android 10\", \"Chipset\": \"Qualcomm SDM675 Snapdragon 675 (11 nm)\", \"CPU\": \"Octa-core (2x2.0 GHz Kryo 460 Gold & 6x1.7 GHz Kryo 460 Silver)\", \"GPU\": \"Adreno 612\"}, \"Memory\": {\"Card slot\": \"microSDXC (uses shared SIM slot)\", \"Internal\": \"128GB 6GB RAM\"}, \"Main Camera\": {\"Triple\": \"48 MP, f/1.8, 26mm (wide), 1/2.0\\\", 0.8\\u00b5m, PDAF\", \"Features\": \"Dual-LED flash, HDR, panorama\", \"Video\": \"4K@30fps, 1080p@30/60/120fps, 720p@960fps, gyro-EIS\"}, \"Selfie camera\": {\"Single\": \"24 MP, f/2.0, 26mm (wide), 1/2.8\\\", 0.9\\u00b5m\", \"Video\": \"1080p@30fps\"}, \"Sound\": {\"Loudspeaker\": \"Yes\", \"3.5mm jack\": \"Yes\"}, \"Comms\": {\"WLAN\": \"Wi-Fi 802.11 a/b/g/n/ac, dual-band, Wi-Fi Direct\", \"Bluetooth\": \"5.0, A2DP, LE, aptX\", \"Positioning\": \"GPS\", \"NFC\": \"Yes\", \"Radio\": \"FM radio\", \"USB\": \"USB Type-C 2.0\"}, \"Features\": {\"Sensors\": \"Fingerprint (rear-mounted), accelerometer, gyro, proximity, compass\"}, \"Battery\": {\"Type\": \"Li-Ion 3820 mAh, non-removable\", \"Charging\": \"18W wired, QC3, 50% in 32 min (advertised)\", \"Stand-by\": \"Up to 396 h (3G)\", \"Talk time\": \"Up to 12 h (2G) / Up to 25 h (3G)\"}, \"Misc\": {\"Colors\": \"Obsidian Black, Opal White\", \"Models\": \"T780H\", \"Price\": \"About 330 EUR\"}, \"Tests\": {\"Loudspeaker\": \"\\r\\n\"}}},\n",
      "{\"phone_brand\": \"doogee\", \"phone_model\": \"Doogee X95\", \"price\": \"About 110 EUR\", \"specs\": {\"Network\": {\"2G bands\": \"GSM 850 / 900 / 1800 / 1900 - SIM 1 & SIM 2\", \"3G bands\": \"HSDPA 900 / 2100 \", \"4G bands\": \"1, 3, 7, 8, 20\", \"Speed\": \"HSPA, LTE\"}, \"Launch\": {\"Announced\": \"2020, April 23\", \"Status\": \"Available. Released 2020, May\"}, \"Body\": {\"Dimensions\": \"167 x 77.4 x 8.9 mm (6.57 x 3.05 x 0.35 in)\", \"Weight\": \"-\", \"SIM\": \"Hybrid Dual SIM (Nano-SIM, dual stand-by)\"}, \"Display\": {\"Type\": \"IPS LCD, 450 nits\", \"Size\": \"6.52 inches, 102.6 cm\", \"Resolution\": \"540 x 1200 pixels, 20:9 ratio (~202 ppi density)\"}, \"Platform\": {\"OS\": \"Android 10\", \"Chipset\": \"Mediatek MT6761V Helio A22 (12 nm)\", \"CPU\": \"Quad-core 1.8 GHz Cortex-A53\", \"GPU\": \"PowerVR GE8300\"}, \"Memory\": {\"Card slot\": \"microSDXC (uses shared SIM slot)\", \"Internal\": \"16GB 3GB RAM\"}, \"Main Camera\": {\"Triple\": \"13 MP, (wide)\", \"Features\": \"LED flash\", \"Video\": \"1080p\"}, \"Selfie camera\": {\"Single\": \"5 MP, f/2.2, (wide)\", \"Video\": \"720p\"}, \"Sound\": {\"Loudspeaker\": \"Yes\", \"3.5mm jack\": \"Yes\"}, \"Comms\": {\"WLAN\": \"Wi-Fi 802.11 b/g/n\", \"Bluetooth\": \"5.2, A2DP, LE\", \"Positioning\": \"GPS, GLONASS, BDS\", \"NFC\": \"No\", \"Radio\": \"FM radio\", \"USB\": \"microUSB 2.0, OTG\"}, \"Features\": {\"Sensors\": \"Accelerometer, proximity\"}, \"Battery\": {\"Type\": \"4350 mAh, non-removable\", \"Charging\": \"10W wired\"}, \"Misc\": {\"Colors\": \"Black, Blue, Green\", \"Price\": \"About 110 EUR\"}}},\n",
      "{\"phone_brand\": \"doogee\", \"phone_model\": \"Doogee S88 Pro\", \"price\": \"About 130 EUR\", \"specs\": {\"Network\": {\"2G bands\": \"GSM 850 / 900 / 1800 / 1900 - SIM 1 & SIM 2\", \"3G bands\": \"HSDPA 850 / 900 / 1700(AWS) / 1900 / 2100 \", \"4G bands\": \"1, 3, 7, 8, 20\", \"Speed\": \"HSPA, LTE\"}, \"Launch\": {\"Announced\": \"2020, June 06\", \"Status\": \"Available. Released 2020, June 06\"}, \"Body\": {\"Dimensions\": \"171.6 x 85.5 x 18.7 mm (6.76 x 3.37 x 0.74 in)\", \"Weight\": \"372 g (13.12 oz)\", \"Build\": \"Glass front (Gorilla Glass), aluminum back with rubber, aluminum frame\", \"SIM\": \"Hybrid Dual SIM (Nano-SIM, dual stand-by)\"}, \"Display\": {\"Type\": \"IPS LCD\", \"Size\": \"6.3 inches, 97.4 cm\", \"Resolution\": \"1080 x 2340 pixels, 19.5:9 ratio (~409 ppi density)\", \"Protection\": \"Corning Gorilla Glass\"}, \"Platform\": {\"OS\": \"Android 10\", \"Chipset\": \"Mediatek MT6771T Helio P70 (12 nm)\", \"CPU\": \"Octa-core (4x2.1 GHz Cortex-A73 & 4x2.0 GHz Cortex-A53)\", \"GPU\": \"Mali-G72 MP3\"}, \"Memory\": {\"Card slot\": \"microSDXC (uses shared SIM slot)\", \"Internal\": \"128GB 6GB RAM\"}, \"Main Camera\": {\"Triple\": \"21 MP, f/2.2, (wide), 1/2.4\\\", 1.12\\u00b5m, PDAF\", \"Features\": \"Dual-LED dual-tone flash, HDR, panorama\", \"Video\": \"1080p@30fps\"}, \"Selfie camera\": {\"Single\": \"16 MP, f/2.2, 26mm (wide)\", \"Video\": \"1080p@30fps\"}, \"Sound\": {\"Loudspeaker\": \"Yes\", \"3.5mm jack\": \"No\"}, \"Comms\": {\"WLAN\": \"Wi-Fi 802.11 b/g/n\", \"Bluetooth\": \"4.2, A2DP\", \"Positioning\": \"GPS, GLONASS, BDS, GALILEO\", \"NFC\": \"Yes\", \"Radio\": \"FM radio\", \"USB\": \"USB Type-C 2.0, OTG\"}, \"Features\": {\"Sensors\": \"Fingerprint (side-mounted), accelerometer, gyro, proximity, compass\"}, \"Battery\": {\"Type\": \"10000 mAh, non-removable\", \"Charging\": \"24W wired\"}, \"Misc\": {\"Colors\": \"Fire Orange, Army Green, Mineral Black\", \"Price\": \"About 130 EUR\"}, \"Tests\": {\"Performance\": \"\\r\\nAnTuTu: 168125 (v8)\", \"Display\": \"\\r\\n\", \"Loudspeaker\": \"\\r\\n\", \"Battery (old)\": \"\\r\\n\"}}},\n",
      "{\"phone_brand\": \"oukitel\", \"phone_model\": \"Oukitel RT2\", \"price\": \"About 350 EUR\", \"specs\": {\"Network\": {\"2G bands\": \"GSM 850 / 900 / 1800 / 1900 - SIM 1 & SIM 2\", \"3G bands\": \"HSDPA 850 / 900 / 1700(AWS) / 1900 / 2100 \", \"4G bands\": \" LTE\", \"Speed\": \"HSPA, LTE\"}, \"Launch\": {\"Announced\": \"2022, September\", \"Status\": \"Available. Released 2022, September\"}, \"Body\": {\"Dimensions\": \"-\", \"Weight\": \"-\", \"SIM\": \"Hybrid Dual SIM (Nano-SIM, dual stand-by)\"}, \"Display\": {\"Type\": \"IPS LCD, 350 nits\", \"Size\": \"10.1 inches, 295.8 cm\", \"Resolution\": \"1200 x 1920 pixels, 16:10 ratio (~224 ppi density)\"}, \"Platform\": {\"OS\": \"Android 12\", \"Chipset\": \"Mediatek MT8788 (12 nm)\", \"CPU\": \"Octa-core (4x2.0 GHz Cortex-A73 & 4x2.0 GHz Cortex-A53)\", \"GPU\": \"Mali-G72 MP3\"}, \"Memory\": {\"Card slot\": \"microSDXC (uses shared SIM slot)\", \"Internal\": \"128GB 8GB RAM\"}, \"Main Camera\": {\"Single\": \"16 MP\", \"Features\": \"LED flash\", \"Video\": \"1080p@30fps\"}, \"Selfie camera\": {\"Single\": \"16 MP\", \"Video\": \"Yes\"}, \"Sound\": {\"Loudspeaker\": \"Yes, with stereo speakers\", \"3.5mm jack\": \"Unspecified\"}, \"Comms\": {\"WLAN\": \"Wi-Fi 802.11 a/b/g/n/ac, dual-band\", \"Bluetooth\": \"4.2, A2DP\", \"Positioning\": \"GPS, GLONASS, GALILEO\", \"NFC\": \"No\", \"Radio\": \"Unspecified\", \"USB\": \"USB Type-C 2.0, OTG\"}, \"Features\": {\"Sensors\": \"Unspecified\"}, \"Battery\": {\"Type\": \"Li-Po 20000 mAh, non-removable\", \"Charging\": \"33W wired\"}, \"Misc\": {\"Colors\": \"Black, Orange\", \"Price\": \"About 350 EUR\"}}},\n",
      "{\"phone_brand\": \"oukitel\", \"phone_model\": \"Oukitel RT1\", \"price\": \"About 220 EUR\", \"specs\": {\"Network\": {\"2G bands\": \"GSM 850 / 900 / 1800 / 1900 - SIM 1 & SIM 2\", \"3G bands\": \"HSDPA 900 / 2100 \", \"4G bands\": \"1, 3, 7, 8, 19, 20\", \"Speed\": \"HSPA, LTE\"}, \"Launch\": {\"Announced\": \"2021, November\", \"Status\": \"Available. Released 2021, December\"}, \"Body\": {\"Dimensions\": \"-\", \"Weight\": \"-\", \"SIM\": \"Hybrid Dual SIM (Nano-SIM, dual stand-by)\"}, \"Display\": {\"Type\": \"IPS LCD\", \"Size\": \"10.1 inches, 295.8 cm\", \"Resolution\": \"1200 x 1920 pixels, 16:10 ratio (~224 ppi density)\"}, \"Platform\": {\"OS\": \"Android 11\", \"Chipset\": \"Mediatek MT8768WA Helio P22 (12 nm)\", \"CPU\": \"Octa-core 2.0 GHz Cortex-A53\", \"GPU\": \"PowerVR GE8320\"}, \"Memory\": {\"Card slot\": \"microSDXC (uses shared SIM slot)\", \"Internal\": \"64GB 4GB RAM\"}, \"Main Camera\": {\"Single\": \"16 MP\", \"Features\": \"LED flash, panorama\", \"Video\": \"1080p@30fps\"}, \"Selfie camera\": {\"Single\": \"16 MP\", \"Video\": \"Yes\"}, \"Sound\": {\"Loudspeaker\": \"Yes\", \"3.5mm jack\": \"Unspecified\"}, \"Comms\": {\"WLAN\": \"Yes\", \"Bluetooth\": \"Yes\", \"Positioning\": \"GPS, GLONASS, GALILEO, BDS\", \"NFC\": \"No\", \"Radio\": \"Unspecified\", \"USB\": \"Yes\"}, \"Features\": {\"Sensors\": \"Unspecified\"}, \"Battery\": {\"Type\": \"Li-Po 10000 mAh, non-removable\"}, \"Misc\": {\"Colors\": \"Black, Orange\", \"Price\": \"About 220 EUR\"}}},\n"
     ]
    }
   ],
   "source": [
    "!head data.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y3VxlzRV8w7r"
   },
   "source": [
    "# DESCRIPCIÓN DEL DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-r3uNjnjCDIN"
   },
   "source": [
    "El dataset cuenta con 2 conjuntos de datos separados en 2 archivos data.json y processed_data2.csv relacionados por la marca y modelo del teléfono.\n",
    "\n",
    "Archivo data.json:\n",
    "\n",
    "Este archivo contiene los datos sin procesar extraídos de GSMArena.com, incluida información sobre varios teléfonos actualmente disponibles en el mercado.\n",
    "\n",
    "\n",
    "- phone_brand: El fabricante o la marca del teléfono (por ejemplo, Apple, Samsung, Xiaomi).\n",
    "- phone_model: El nombre o número de modelo específico del teléfono.\n",
    "- Precio: El precio del teléfono, que puede ser una cifra exacta o una estimación aproximada. Nota: Los datos de precios pueden requerir una revisión.\n",
    "- especificaciones: Un diccionario de diccionarios que detalla las especificaciones técnicas del teléfono, incluidas características como el tamaño de la pantalla, la resolución de la cámara, el procesador, la duración de la batería y más.\n",
    "- precios: Un diccionario de diccionarios que contiene listas de precios del teléfono en varios sitios web de comercio electrónico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "ok",
     "timestamp": 1734609403663,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "9CjaG8888fRj",
    "outputId": "7fce9673-dba7-48aa-8717-6eefd7cfddb4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"df_J\",\n  \"rows\": 8792,\n  \"fields\": [\n    {\n      \"column\": \"phone_brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 36,\n        \"samples\": [\n          \"samsung\",\n          \"energizer\",\n          \"lenovo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phone_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8722,\n        \"samples\": [\n          \"Infinix S5 Pro (48+40)\",\n          \"Huawei G7010\",\n          \"Samsung Galaxy Pocket plus S5301\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 921,\n        \"samples\": [\n          \"About 1170 EUR\",\n          \"\\u00a3\\u2009126.74 / \\u20ac\\u2009145.00 / \\u20b9\\u200911,496\",\n          \"\\u20ac\\u200973.99 / \\u00a3\\u200969.99\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"specs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pricing\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "df_J"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3777103c-fca2-428d-a1c4-5cd7ca4bfb46\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>phone_model</th>\n",
       "      <th>price</th>\n",
       "      <th>specs</th>\n",
       "      <th>pricing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>itel</td>\n",
       "      <td>itel Smart Watch 1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'Network': {'2G bands': ' N/A', '3G bands': '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oukitel</td>\n",
       "      <td>Oukitel WP19</td>\n",
       "      <td>About 380 EUR</td>\n",
       "      <td>{'Network': {'2G bands': 'GSM 850 / 900 / 1800...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cubot</td>\n",
       "      <td>Cubot Smart Watch</td>\n",
       "      <td>None</td>\n",
       "      <td>{'Network': {'2G bands': ' N/A', '3G bands': '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cubot</td>\n",
       "      <td>Cubot ID206</td>\n",
       "      <td>None</td>\n",
       "      <td>{'Network': {'2G bands': ' N/A', '3G bands': '...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tcl</td>\n",
       "      <td>TCL Plex</td>\n",
       "      <td>About 330 EUR</td>\n",
       "      <td>{'Network': {'2G bands': 'GSM 850 / 900 / 1800...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3777103c-fca2-428d-a1c4-5cd7ca4bfb46')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3777103c-fca2-428d-a1c4-5cd7ca4bfb46 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3777103c-fca2-428d-a1c4-5cd7ca4bfb46');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-60f4effe-4720-4724-85db-6b7855691258\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-60f4effe-4720-4724-85db-6b7855691258')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-60f4effe-4720-4724-85db-6b7855691258 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  phone_brand         phone_model          price  \\\n",
       "0        itel  itel Smart Watch 1           None   \n",
       "1     oukitel        Oukitel WP19  About 380 EUR   \n",
       "2       cubot   Cubot Smart Watch           None   \n",
       "3       cubot         Cubot ID206           None   \n",
       "4         tcl            TCL Plex  About 330 EUR   \n",
       "\n",
       "                                               specs pricing  \n",
       "0  {'Network': {'2G bands': ' N/A', '3G bands': '...     NaN  \n",
       "1  {'Network': {'2G bands': 'GSM 850 / 900 / 1800...     NaN  \n",
       "2  {'Network': {'2G bands': ' N/A', '3G bands': '...     NaN  \n",
       "3  {'Network': {'2G bands': ' N/A', '3G bands': '...     NaN  \n",
       "4  {'Network': {'2G bands': 'GSM 850 / 900 / 1800...     NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_J.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfyCtgKW89vo"
   },
   "source": [
    "Archivo processed_data2.csv:\n",
    "\n",
    "Este archivo contiene datos limpios y procesado sobre teléfonos, con información de varias plataformas de comercio electrónico.\n",
    "\n",
    "- phone_brand: El fabricante o la marca del teléfono (por ejemplo, Apple, Samsung, Xiaomi).\n",
    "- phone_model: El nombre o número de modelo específico del teléfono.\n",
    "- tienda: La tienda específica donde se encuentra listado el teléfono.\n",
    "- precio: el precio del teléfono en forma de número de punto flotante en la moneda local. Esta columna siempre debe analizarse junto con la currencycolumna\n",
    "- Moneda: La moneda en la que se establece el precio (por ejemplo, USD, EUR).\n",
    "- price_USD: El precio del teléfono convertido a USD.\n",
    "- almacenamiento: La cantidad de almacenamiento en GB (entero).\n",
    "- ram: La cantidad de RAM en GB (entero).\n",
    "- Lanzamiento: La fecha de lanzamiento del teléfono (en formato de fecha y hora).\n",
    "- Dimensiones: Las dimensiones exactas del teléfono, por ejemplo: 163.8 x 76.8 x 8.9 mm (6.45 x 3.02 x 0.35 in).\n",
    "- Peso: El peso del teléfono en gramos (flotante).\n",
    "- Display_Type: El tipo de visualización, por ejemplo: LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolby Vision, 1000 nits (typ), 2000 nits (HBM).\n",
    "- Display_Size: El tamaño de la pantalla en pulgadas.\n",
    "- Display_Resolution: La resolución de la pantalla, por ejemplo: 1280 x 2856.\n",
    "- SO: El sistema operativo del teléfono, por ejemplo: iOS 18, Android 14.\n",
    "- NFC: Una bandera que indica si el teléfono tiene NFC: 1- Tiene NFC, 0- No tiene NFC.\n",
    "- USB: El tipo de USB, por ejemplo: USB Type-C 3.2 Gen 2, DisplayPort.\n",
    "- BATERÍA: La capacidad de la batería en mAh.\n",
    "- Características_Sensores: Características y sensores incluidos en el teléfono.\n",
    "- Colores: Las opciones de color para el modelo de teléfono, por ejemplo: Black Titanium, White Titanium, Natural Titanium, Desert Titanium.\n",
    "- Vídeo: Especificaciones de la cámara para grabación de vídeo, por ejemplo:4K@24/25/30/60/100/120fps, 1080p@25/30/60/120/240fps, 10-bit HDR, Dolby Vision HDR (up to 60fps), ProRes, 3D (spatial) video/audio, stereo sound rec.\n",
    "- Chipset: El chipset utilizado en el teléfono, por ejemplo: Apple A18 Pro (3 nm).\n",
    "- CPU: Las especificaciones de la CPU, por ejemplo: Hexa-core (2x4.05 GHz + 4x2.42 GHz).\n",
    "- GPU: Las especificaciones de la GPU, por ejemplo: Apple GPU (6-core graphics).\n",
    "- Año: El año en el que se lanzó el modelo de teléfono.\n",
    "- Plegable: Una bandera que indica si el teléfono es plegable: 1- El teléfono es plegable, 0- El teléfono no es plegable.\n",
    "- PPI_Density: La densidad de píxeles en píxeles por pulgada (ppi).\n",
    "- quantile_10: El décimo cuartil del precio de los teléfonos en un año determinado.\n",
    "- quantile_50: El 50.º cuartil (mediana) del precio de los teléfonos en un año determinado.\n",
    "- quantile_90: El cuartil 90 del precio de los teléfonos en un año determinado.\n",
    "- price_range: Clasificación del rango de precios ( low price, medium price, high price), basada en cuantiles en un año determinado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1734609403663,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "o0kX0prE8c5K",
    "outputId": "fa04ba92-3aed-4c26-eb49-0875941ca101"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "df"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-af711dbe-7cfd-441e-966c-dcfd76064bc5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone_brand</th>\n",
       "      <th>phone_model</th>\n",
       "      <th>store</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>storage</th>\n",
       "      <th>ram</th>\n",
       "      <th>launch_date</th>\n",
       "      <th>dimensions</th>\n",
       "      <th>weight</th>\n",
       "      <th>display_type</th>\n",
       "      <th>...</th>\n",
       "      <th>price_range</th>\n",
       "      <th>os_type</th>\n",
       "      <th>os_version</th>\n",
       "      <th>battery_size</th>\n",
       "      <th>colors_available</th>\n",
       "      <th>chip_company</th>\n",
       "      <th>cpu_core</th>\n",
       "      <th>gpu_company</th>\n",
       "      <th>fingerprint</th>\n",
       "      <th>video_resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>Apple iPhone 16 Pro</td>\n",
       "      <td>Amazon DE</td>\n",
       "      <td>1357.55</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in)</td>\n",
       "      <td>199.0</td>\n",
       "      <td>LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...</td>\n",
       "      <td>...</td>\n",
       "      <td>medium price</td>\n",
       "      <td>iOS</td>\n",
       "      <td>18</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Hexa-core</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Face</td>\n",
       "      <td>4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>Apple iPhone 16 Pro</td>\n",
       "      <td>Amazon DE</td>\n",
       "      <td>1492.55</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in)</td>\n",
       "      <td>199.0</td>\n",
       "      <td>LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...</td>\n",
       "      <td>...</td>\n",
       "      <td>high price</td>\n",
       "      <td>iOS</td>\n",
       "      <td>18</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Hexa-core</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Face</td>\n",
       "      <td>4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>Apple iPhone 16 Pro</td>\n",
       "      <td>Amazon DE</td>\n",
       "      <td>1705.32</td>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in)</td>\n",
       "      <td>199.0</td>\n",
       "      <td>LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...</td>\n",
       "      <td>...</td>\n",
       "      <td>high price</td>\n",
       "      <td>iOS</td>\n",
       "      <td>18</td>\n",
       "      <td>Medium</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Hexa-core</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Face</td>\n",
       "      <td>4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>Apple iPhone 16 Pro Max</td>\n",
       "      <td>Amazon DE</td>\n",
       "      <td>1564.92</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-09-20</td>\n",
       "      <td>163 x 77.6 x 8.3 mm (6.42 x 3.06 x 0.33 in)</td>\n",
       "      <td>227.0</td>\n",
       "      <td>LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...</td>\n",
       "      <td>...</td>\n",
       "      <td>high price</td>\n",
       "      <td>iOS</td>\n",
       "      <td>18</td>\n",
       "      <td>Large</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Hexa-core</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Face</td>\n",
       "      <td>4K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>Apple iPhone 12 mini</td>\n",
       "      <td>Amazon DE</td>\n",
       "      <td>247.32</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>131.5 x 64.2 x 7.4 mm (5.18 x 2.53 x 0.29 in)</td>\n",
       "      <td>135.0</td>\n",
       "      <td>Super Retina XDR OLED, HDR10, Dolby Vision, 62...</td>\n",
       "      <td>...</td>\n",
       "      <td>medium price</td>\n",
       "      <td>iOS</td>\n",
       "      <td>14.1</td>\n",
       "      <td>Small</td>\n",
       "      <td>6</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Hexa-core</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Face</td>\n",
       "      <td>4K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af711dbe-7cfd-441e-966c-dcfd76064bc5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-af711dbe-7cfd-441e-966c-dcfd76064bc5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-af711dbe-7cfd-441e-966c-dcfd76064bc5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-dc87096a-473a-4faf-a90c-763f4001546c\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc87096a-473a-4faf-a90c-763f4001546c')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-dc87096a-473a-4faf-a90c-763f4001546c button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  phone_brand              phone_model      store  price_usd  storage  ram  \\\n",
       "0       apple      Apple iPhone 16 Pro  Amazon DE    1357.55      256    8   \n",
       "1       apple      Apple iPhone 16 Pro  Amazon DE    1492.55      512    8   \n",
       "2       apple      Apple iPhone 16 Pro  Amazon DE    1705.32     1000    8   \n",
       "3       apple  Apple iPhone 16 Pro Max  Amazon DE    1564.92      512    8   \n",
       "4       apple     Apple iPhone 12 mini  Amazon DE     247.32      128    4   \n",
       "\n",
       "  launch_date                                     dimensions  weight  \\\n",
       "0  2024-09-20  149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in)   199.0   \n",
       "1  2024-09-20  149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in)   199.0   \n",
       "2  2024-09-20  149.6 x 71.5 x 8.3 mm (5.89 x 2.81 x 0.33 in)   199.0   \n",
       "3  2024-09-20    163 x 77.6 x 8.3 mm (6.42 x 3.06 x 0.33 in)   227.0   \n",
       "4  2020-11-13  131.5 x 64.2 x 7.4 mm (5.18 x 2.53 x 0.29 in)   135.0   \n",
       "\n",
       "                                        display_type  ...   price_range  \\\n",
       "0  LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...  ...  medium price   \n",
       "1  LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...  ...    high price   \n",
       "2  LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...  ...    high price   \n",
       "3  LTPO Super Retina XDR OLED, 120Hz, HDR10, Dolb...  ...    high price   \n",
       "4  Super Retina XDR OLED, HDR10, Dolby Vision, 62...  ...  medium price   \n",
       "\n",
       "  os_type os_version  battery_size colors_available  chip_company   cpu_core  \\\n",
       "0     iOS         18        Medium                4         Apple  Hexa-core   \n",
       "1     iOS         18        Medium                4         Apple  Hexa-core   \n",
       "2     iOS         18        Medium                4         Apple  Hexa-core   \n",
       "3     iOS         18         Large                4         Apple  Hexa-core   \n",
       "4     iOS       14.1         Small                6         Apple  Hexa-core   \n",
       "\n",
       "  gpu_company fingerprint video_resolution  \n",
       "0       Apple        Face               4K  \n",
       "1       Apple        Face               4K  \n",
       "2       Apple        Face               4K  \n",
       "3       Apple        Face               4K  \n",
       "4       Apple        Face               4K  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvxSN6ZDCk_O"
   },
   "source": [
    "# Copiar archivos al sistema HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBMzrVffCtyg"
   },
   "source": [
    "## Instalación de Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8ufklo5EE5h"
   },
   "source": [
    "El primer paso será instalar Hadoop, este framework nos montará un sistema de archivos HDFS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O37mzPIyFr-t"
   },
   "source": [
    "Nos descargamos el paquete instalador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25693,
     "status": "ok",
     "timestamp": 1734609429350,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "eE0BnXt3Fu7o",
    "outputId": "1ef41cca-35bc-4c9f-ea6f-8596e529c93c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-12-19 11:56:35--  https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz\n",
      "Resolving downloads.apache.org (downloads.apache.org)... 88.99.208.237, 135.181.214.104, 2a01:4f8:10a:39da::2, ...\n",
      "Connecting to downloads.apache.org (downloads.apache.org)|88.99.208.237|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 730107476 (696M) [application/x-gzip]\n",
      "Saving to: ‘hadoop-3.3.6.tar.gz’\n",
      "\n",
      "hadoop-3.3.6.tar.gz 100%[===================>] 696.28M  27.6MB/s    in 25s     \n",
      "\n",
      "2024-12-19 11:57:01 (27.8 MB/s) - ‘hadoop-3.3.6.tar.gz’ saved [730107476/730107476]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMpKm0xTFwoY"
   },
   "source": [
    "Descomprimimos el contenido del archivo descargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14423,
     "status": "ok",
     "timestamp": 1734609443771,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "t0pyn6G2F0zd"
   },
   "outputs": [],
   "source": [
    "!tar -xzf hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBWFNkk6GEOB"
   },
   "source": [
    "Una vez tenemos el contenido descomprimido, eliminamos el archivo descargado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1734609444085,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "ikgSHr6pGBZk"
   },
   "outputs": [],
   "source": [
    "!rm hadoop-3.3.6.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em8Sx6khGyfk"
   },
   "source": [
    "Movemos la carpeta descomprimida a la ruta /usr/local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1734609444085,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "L5VBtG2EGeE-"
   },
   "outputs": [],
   "source": [
    "!mv  hadoop-3.3.6/ /usr/local/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UwppigmG6tB"
   },
   "source": [
    "Actuzlizamos al path del sistema para poder utilizar hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1734609444085,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "CxWAQtj1G29V"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = os.environ[\"PATH\"] + \":\" + \"/usr/local/hadoop-3.3.6/bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hT1TNMnKOJyb"
   },
   "source": [
    "Comprobamos que ya podemos ejecutar hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1564,
     "status": "ok",
     "timestamp": 1734609445647,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "xYSW4HtqKC5J",
    "outputId": "b6dd3567-6cb6-4496-de9b-0379ae4784c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hadoop 3.3.6\n",
      "Source code repository https://github.com/apache/hadoop.git -r 1be78238728da9266a4f88195058f08fd012bf9c\n",
      "Compiled by ubuntu on 2023-06-18T08:22Z\n",
      "Compiled on platform linux-x86_64\n",
      "Compiled with protoc 3.7.1\n",
      "From source with checksum 5652179ad55f76cb287d9c633bb53bbd\n",
      "This command was run using /usr/local/hadoop-3.3.6/share/hadoop/common/hadoop-common-3.3.6.jar\n"
     ]
    }
   ],
   "source": [
    "!hadoop version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7rYYPk8TjAc"
   },
   "source": [
    "## Subir los archivos a hdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-hywS1_Tpo1"
   },
   "source": [
    "Creamos una carpeta en el entorno de hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3230,
     "status": "ok",
     "timestamp": 1734609448875,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "h6YJrW_iRocB"
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -mkdir /dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7sf88gdTtcH"
   },
   "source": [
    "Subimos ambos archivos a la carpeta creada dentro de hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 2127,
     "status": "ok",
     "timestamp": 1734609450999,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "pDEX2V46TXYh"
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -put processed_data2.csv /dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 2252,
     "status": "ok",
     "timestamp": 1734609453249,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "j4FR1mpdTdSJ"
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -put data.json /dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PaJ8oxWsTxec"
   },
   "source": [
    "Comprobamos que los 2 archivos están subidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2099,
     "status": "ok",
     "timestamp": 1734609455346,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "cEfc0vsWTz-v",
    "outputId": "1f348b34-d7b0-42ff-ecfd-dcc8398e6e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root root   14322766 2024-12-19 11:57 /dataset/data.json\n",
      "-rw-r--r--   1 root root    1082761 2024-12-19 11:57 /dataset/processed_data2.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CggsjDcbUYSW"
   },
   "source": [
    "# Conteo mediante grep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zL2jPEXCUk5w"
   },
   "source": [
    "Analizaremos el arhivo processed_data2.csv y contaremos las veces que aparece la palabra Apple y la palabra Samsung y así podemos ver cuantos modelos de cada marca hay en el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBfBjJV2ExWj"
   },
   "source": [
    "Guardamos el resultado en hdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7437,
     "status": "ok",
     "timestamp": 1734609462781,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "C32snsPlWFNY",
    "outputId": "e199aa82-426f-42c2-92cb-2f34abb996df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:57:29,254 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2024-12-19 11:57:29,535 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-12-19 11:57:29,536 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2024-12-19 11:57:29,912 INFO input.FileInputFormat: Total input files to process : 2\n",
      "2024-12-19 11:57:29,963 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2024-12-19 11:57:30,573 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local691720336_0001\n",
      "2024-12-19 11:57:30,573 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-12-19 11:57:31,063 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-12-19 11:57:31,064 INFO mapreduce.Job: Running job: job_local691720336_0001\n",
      "2024-12-19 11:57:31,115 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-12-19 11:57:31,132 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:31,133 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:31,133 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:31,135 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-12-19 11:57:31,286 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-12-19 11:57:31,287 INFO mapred.LocalJobRunner: Starting task: attempt_local691720336_0001_m_000000_0\n",
      "2024-12-19 11:57:31,424 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:31,428 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:31,429 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:31,492 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:31,508 INFO mapred.MapTask: Processing split: file:/dataset/data.json:0+14322766\n",
      "2024-12-19 11:57:31,724 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:31,724 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:31,724 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:31,724 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:31,724 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:31,741 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:32,081 INFO mapreduce.Job: Job job_local691720336_0001 running in uber mode : false\n",
      "2024-12-19 11:57:32,086 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2024-12-19 11:57:32,324 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:32,332 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:32,333 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:32,333 INFO mapred.MapTask: bufstart = 0; bufend = 1792; bufvoid = 104857600\n",
      "2024-12-19 11:57:32,333 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213888(104855552); length = 509/6553600\n",
      "2024-12-19 11:57:32,357 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:32,388 INFO mapred.Task: Task:attempt_local691720336_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:32,397 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:32,397 INFO mapred.Task: Task 'attempt_local691720336_0001_m_000000_0' done.\n",
      "2024-12-19 11:57:32,411 INFO mapred.Task: Final Counters for attempt_local691720336_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=14716289\n",
      "\t\tFILE: Number of bytes written=917568\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=8794\n",
      "\t\tMap output records=128\n",
      "\t\tMap output bytes=1792\n",
      "\t\tMap output materialized bytes=22\n",
      "\t\tInput split bytes=88\n",
      "\t\tCombine input records=128\n",
      "\t\tCombine output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=25\n",
      "\t\tTotal committed heap usage (bytes)=369098752\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=14434682\n",
      "2024-12-19 11:57:32,412 INFO mapred.LocalJobRunner: Finishing task: attempt_local691720336_0001_m_000000_0\n",
      "2024-12-19 11:57:32,413 INFO mapred.LocalJobRunner: Starting task: attempt_local691720336_0001_m_000001_0\n",
      "2024-12-19 11:57:32,415 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:32,415 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:32,415 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:32,415 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:32,418 INFO mapred.MapTask: Processing split: file:/dataset/processed_data2.csv:0+1082761\n",
      "2024-12-19 11:57:32,461 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:32,462 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:32,462 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:32,462 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:32,462 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:32,464 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:32,584 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:32,592 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:32,592 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:32,593 INFO mapred.MapTask: bufstart = 0; bufend = 2716; bufvoid = 104857600\n",
      "2024-12-19 11:57:32,593 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213624(104854496); length = 773/6553600\n",
      "2024-12-19 11:57:32,598 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:32,610 INFO mapred.Task: Task:attempt_local691720336_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:32,617 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:32,617 INFO mapred.Task: Task 'attempt_local691720336_0001_m_000001_0' done.\n",
      "2024-12-19 11:57:32,618 INFO mapred.Task: Final Counters for attempt_local691720336_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15807727\n",
      "\t\tFILE: Number of bytes written=917622\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1709\n",
      "\t\tMap output records=194\n",
      "\t\tMap output bytes=2716\n",
      "\t\tMap output materialized bytes=22\n",
      "\t\tInput split bytes=98\n",
      "\t\tCombine input records=194\n",
      "\t\tCombine output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=8\n",
      "\t\tTotal committed heap usage (bytes)=369098752\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1091233\n",
      "2024-12-19 11:57:32,618 INFO mapred.LocalJobRunner: Finishing task: attempt_local691720336_0001_m_000001_0\n",
      "2024-12-19 11:57:32,618 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-12-19 11:57:32,634 INFO mapred.LocalJobRunner: Starting task: attempt_local691720336_0001_r_000000_0\n",
      "2024-12-19 11:57:32,636 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-12-19 11:57:32,661 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:32,661 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:32,661 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:32,662 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:32,665 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38b7e7fb\n",
      "2024-12-19 11:57:32,670 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:32,719 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-12-19 11:57:32,725 INFO reduce.EventFetcher: attempt_local691720336_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-12-19 11:57:32,806 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local691720336_0001_m_000001_0 decomp: 18 len: 22 to MEMORY\n",
      "2024-12-19 11:57:32,812 INFO reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local691720336_0001_m_000001_0\n",
      "2024-12-19 11:57:32,819 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18\n",
      "2024-12-19 11:57:32,830 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local691720336_0001_m_000000_0 decomp: 18 len: 22 to MEMORY\n",
      "2024-12-19 11:57:32,838 INFO reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local691720336_0001_m_000000_0\n",
      "2024-12-19 11:57:32,840 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 2, commitMemory -> 18, usedMemory ->36\n",
      "2024-12-19 11:57:32,840 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-12-19 11:57:32,843 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:32,843 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-12-19 11:57:32,859 INFO mapred.Merger: Merging 2 sorted segments\n",
      "2024-12-19 11:57:32,860 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 20 bytes\n",
      "2024-12-19 11:57:32,867 INFO reduce.MergeManagerImpl: Merged 2 segments, 36 bytes to disk to satisfy reduce memory limit\n",
      "2024-12-19 11:57:32,868 INFO reduce.MergeManagerImpl: Merging 1 files, 38 bytes from disk\n",
      "2024-12-19 11:57:32,869 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-12-19 11:57:32,869 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:32,871 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 26 bytes\n",
      "2024-12-19 11:57:32,872 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:32,926 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-12-19 11:57:32,935 INFO mapred.Task: Task:attempt_local691720336_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:32,943 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:32,943 INFO mapred.Task: Task attempt_local691720336_0001_r_000000_0 is allowed to commit now\n",
      "2024-12-19 11:57:32,946 INFO output.FileOutputCommitter: Saved output of task 'attempt_local691720336_0001_r_000000_0' to file:/content/grep-temp-1516108476\n",
      "2024-12-19 11:57:32,951 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-12-19 11:57:32,951 INFO mapred.Task: Task 'attempt_local691720336_0001_r_000000_0' done.\n",
      "2024-12-19 11:57:32,953 INFO mapred.Task: Final Counters for attempt_local691720336_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15807873\n",
      "\t\tFILE: Number of bytes written=917780\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=44\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=369098752\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=120\n",
      "2024-12-19 11:57:32,953 INFO mapred.LocalJobRunner: Finishing task: attempt_local691720336_0001_r_000000_0\n",
      "2024-12-19 11:57:32,954 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-12-19 11:57:33,098 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-12-19 11:57:33,098 INFO mapreduce.Job: Job job_local691720336_0001 completed successfully\n",
      "2024-12-19 11:57:33,123 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=46331889\n",
      "\t\tFILE: Number of bytes written=2752970\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10503\n",
      "\t\tMap output records=322\n",
      "\t\tMap output bytes=4508\n",
      "\t\tMap output materialized bytes=44\n",
      "\t\tInput split bytes=186\n",
      "\t\tCombine input records=322\n",
      "\t\tCombine output records=2\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=44\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=33\n",
      "\t\tTotal committed heap usage (bytes)=1107296256\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=15525915\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=120\n",
      "2024-12-19 11:57:33,199 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:33,235 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2024-12-19 11:57:33,245 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "2024-12-19 11:57:33,303 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1187459023_0002\n",
      "2024-12-19 11:57:33,303 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-12-19 11:57:33,436 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-12-19 11:57:33,437 INFO mapreduce.Job: Running job: job_local1187459023_0002\n",
      "2024-12-19 11:57:33,437 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-12-19 11:57:33,438 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:33,438 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:33,438 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:33,439 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-12-19 11:57:33,444 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-12-19 11:57:33,445 INFO mapred.LocalJobRunner: Starting task: attempt_local1187459023_0002_m_000000_0\n",
      "2024-12-19 11:57:33,447 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:33,448 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:33,448 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:33,448 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:33,456 INFO mapred.MapTask: Processing split: file:/content/grep-temp-1516108476/part-r-00000:0+108\n",
      "2024-12-19 11:57:33,518 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:33,518 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:33,518 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:33,518 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:33,518 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:33,530 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:33,546 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:33,550 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:33,550 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:33,550 INFO mapred.MapTask: bufstart = 0; bufend = 14; bufvoid = 104857600\n",
      "2024-12-19 11:57:33,550 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2024-12-19 11:57:33,552 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:33,555 INFO mapred.Task: Task:attempt_local1187459023_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:33,558 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:33,558 INFO mapred.Task: Task 'attempt_local1187459023_0002_m_000000_0' done.\n",
      "2024-12-19 11:57:33,558 INFO mapred.Task: Final Counters for attempt_local1187459023_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=16089507\n",
      "\t\tFILE: Number of bytes written=1837042\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=14\n",
      "\t\tMap output materialized bytes=22\n",
      "\t\tInput split bytes=112\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=369098752\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=120\n",
      "2024-12-19 11:57:33,558 INFO mapred.LocalJobRunner: Finishing task: attempt_local1187459023_0002_m_000000_0\n",
      "2024-12-19 11:57:33,558 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-12-19 11:57:33,560 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-12-19 11:57:33,561 INFO mapred.LocalJobRunner: Starting task: attempt_local1187459023_0002_r_000000_0\n",
      "2024-12-19 11:57:33,563 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:33,564 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:33,564 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:33,564 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:33,564 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4a1b7964\n",
      "2024-12-19 11:57:33,567 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:33,569 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-12-19 11:57:33,572 INFO reduce.EventFetcher: attempt_local1187459023_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-12-19 11:57:33,581 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local1187459023_0002_m_000000_0 decomp: 18 len: 22 to MEMORY\n",
      "2024-12-19 11:57:33,582 INFO reduce.InMemoryMapOutput: Read 18 bytes from map-output for attempt_local1187459023_0002_m_000000_0\n",
      "2024-12-19 11:57:33,583 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 18, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->18\n",
      "2024-12-19 11:57:33,583 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-12-19 11:57:33,584 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-12-19 11:57:33,584 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-12-19 11:57:33,586 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:33,586 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8 bytes\n",
      "2024-12-19 11:57:33,587 INFO reduce.MergeManagerImpl: Merged 1 segments, 18 bytes to disk to satisfy reduce memory limit\n",
      "2024-12-19 11:57:33,588 INFO reduce.MergeManagerImpl: Merging 1 files, 22 bytes from disk\n",
      "2024-12-19 11:57:33,588 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-12-19 11:57:33,588 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:33,588 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 8 bytes\n",
      "2024-12-19 11:57:33,589 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-12-19 11:57:33,593 INFO mapred.Task: Task:attempt_local1187459023_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:33,594 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-12-19 11:57:33,594 INFO mapred.Task: Task attempt_local1187459023_0002_r_000000_0 is allowed to commit now\n",
      "2024-12-19 11:57:33,596 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1187459023_0002_r_000000_0' to file:/content/grep_apple\n",
      "2024-12-19 11:57:33,598 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-12-19 11:57:33,598 INFO mapred.Task: Task 'attempt_local1187459023_0002_r_000000_0' done.\n",
      "2024-12-19 11:57:33,599 INFO mapred.Task: Final Counters for attempt_local1187459023_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=16089583\n",
      "\t\tFILE: Number of bytes written=1837086\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=22\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=369098752\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=22\n",
      "2024-12-19 11:57:33,600 INFO mapred.LocalJobRunner: Finishing task: attempt_local1187459023_0002_r_000000_0\n",
      "2024-12-19 11:57:33,600 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-12-19 11:57:34,437 INFO mapreduce.Job: Job job_local1187459023_0002 running in uber mode : false\n",
      "2024-12-19 11:57:34,438 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-12-19 11:57:34,438 INFO mapreduce.Job: Job job_local1187459023_0002 completed successfully\n",
      "2024-12-19 11:57:34,443 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=32179090\n",
      "\t\tFILE: Number of bytes written=3674128\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=14\n",
      "\t\tMap output materialized bytes=22\n",
      "\t\tInput split bytes=112\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=22\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=738197504\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=120\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=22\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar grep /dataset grep_apple 'apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2021,
     "status": "ok",
     "timestamp": 1734609464799,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "SSVWS91UW3ef",
    "outputId": "a4b1c258-250a-432c-e37b-43b2948c6462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root root          0 2024-12-19 11:57 grep_apple/_SUCCESS\n",
      "-rw-r--r--   1 root root         10 2024-12-19 11:57 grep_apple/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls grep_apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2218,
     "status": "ok",
     "timestamp": 1734609467015,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "B1kDEETeZmT1",
    "outputId": "ce7cef6c-0faf-4abb-a934-ebdedae43d59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\tapple\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat grep_apple/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4Wdf3PKE-Zy"
   },
   "source": [
    "Guardamos el resultado en local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6779,
     "status": "ok",
     "timestamp": 1734609473792,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "7tdJ4VTEWivu",
    "outputId": "6fd5e836-9f30-4e53-d60c-5abbf7197275"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:57:40,721 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2024-12-19 11:57:40,913 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-12-19 11:57:40,913 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2024-12-19 11:57:41,248 INFO input.FileInputFormat: Total input files to process : 2\n",
      "2024-12-19 11:57:41,295 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2024-12-19 11:57:41,606 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1255638818_0001\n",
      "2024-12-19 11:57:41,606 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-12-19 11:57:41,884 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-12-19 11:57:41,885 INFO mapreduce.Job: Running job: job_local1255638818_0001\n",
      "2024-12-19 11:57:41,894 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-12-19 11:57:41,903 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:41,905 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:41,905 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:41,907 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-12-19 11:57:41,985 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-12-19 11:57:41,986 INFO mapred.LocalJobRunner: Starting task: attempt_local1255638818_0001_m_000000_0\n",
      "2024-12-19 11:57:42,045 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:42,045 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:42,048 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:42,078 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:42,089 INFO mapred.MapTask: Processing split: file:/dataset/data.json:0+14322766\n",
      "2024-12-19 11:57:42,173 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:42,173 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:42,173 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:42,173 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:42,173 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:42,181 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:42,492 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:42,493 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:42,493 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:42,494 INFO mapred.MapTask: bufstart = 0; bufend = 22400; bufvoid = 104857600\n",
      "2024-12-19 11:57:42,494 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26208800(104835200); length = 5597/6553600\n",
      "2024-12-19 11:57:42,530 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:42,550 INFO mapred.Task: Task:attempt_local1255638818_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:42,553 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:42,553 INFO mapred.Task: Task 'attempt_local1255638818_0001_m_000000_0' done.\n",
      "2024-12-19 11:57:42,563 INFO mapred.Task: Final Counters for attempt_local1255638818_0001_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=14716289\n",
      "\t\tFILE: Number of bytes written=920648\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=8794\n",
      "\t\tMap output records=1400\n",
      "\t\tMap output bytes=22400\n",
      "\t\tMap output materialized bytes=24\n",
      "\t\tInput split bytes=88\n",
      "\t\tCombine input records=1400\n",
      "\t\tCombine output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=13\n",
      "\t\tTotal committed heap usage (bytes)=361758720\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=14434682\n",
      "2024-12-19 11:57:42,563 INFO mapred.LocalJobRunner: Finishing task: attempt_local1255638818_0001_m_000000_0\n",
      "2024-12-19 11:57:42,564 INFO mapred.LocalJobRunner: Starting task: attempt_local1255638818_0001_m_000001_0\n",
      "2024-12-19 11:57:42,566 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:42,566 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:42,566 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:42,566 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:42,571 INFO mapred.MapTask: Processing split: file:/dataset/processed_data2.csv:0+1082761\n",
      "2024-12-19 11:57:42,629 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:42,629 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:42,629 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:42,629 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:42,629 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:42,644 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:42,728 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:42,730 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:42,730 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:42,730 INFO mapred.MapTask: bufstart = 0; bufend = 6848; bufvoid = 104857600\n",
      "2024-12-19 11:57:42,730 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212688(104850752); length = 1709/6553600\n",
      "2024-12-19 11:57:42,739 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:42,742 INFO mapred.Task: Task:attempt_local1255638818_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:42,745 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:42,746 INFO mapred.Task: Task 'attempt_local1255638818_0001_m_000001_0' done.\n",
      "2024-12-19 11:57:42,747 INFO mapred.Task: Final Counters for attempt_local1255638818_0001_m_000001_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15807727\n",
      "\t\tFILE: Number of bytes written=920704\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1709\n",
      "\t\tMap output records=428\n",
      "\t\tMap output bytes=6848\n",
      "\t\tMap output materialized bytes=24\n",
      "\t\tInput split bytes=98\n",
      "\t\tCombine input records=428\n",
      "\t\tCombine output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=26\n",
      "\t\tTotal committed heap usage (bytes)=361758720\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1091233\n",
      "2024-12-19 11:57:42,747 INFO mapred.LocalJobRunner: Finishing task: attempt_local1255638818_0001_m_000001_0\n",
      "2024-12-19 11:57:42,748 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-12-19 11:57:42,753 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-12-19 11:57:42,757 INFO mapred.LocalJobRunner: Starting task: attempt_local1255638818_0001_r_000000_0\n",
      "2024-12-19 11:57:42,772 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:42,772 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:42,772 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:42,772 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:42,783 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@20eaa4ac\n",
      "2024-12-19 11:57:42,786 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:42,810 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-12-19 11:57:42,819 INFO reduce.EventFetcher: attempt_local1255638818_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-12-19 11:57:42,853 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1255638818_0001_m_000000_0 decomp: 20 len: 24 to MEMORY\n",
      "2024-12-19 11:57:42,857 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local1255638818_0001_m_000000_0\n",
      "2024-12-19 11:57:42,862 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20\n",
      "2024-12-19 11:57:42,869 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1255638818_0001_m_000001_0 decomp: 20 len: 24 to MEMORY\n",
      "2024-12-19 11:57:42,871 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local1255638818_0001_m_000001_0\n",
      "2024-12-19 11:57:42,872 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 2, commitMemory -> 20, usedMemory ->40\n",
      "2024-12-19 11:57:42,872 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-12-19 11:57:42,874 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:42,874 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-12-19 11:57:42,882 INFO mapred.Merger: Merging 2 sorted segments\n",
      "2024-12-19 11:57:42,883 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 20 bytes\n",
      "2024-12-19 11:57:42,884 INFO reduce.MergeManagerImpl: Merged 2 segments, 40 bytes to disk to satisfy reduce memory limit\n",
      "2024-12-19 11:57:42,889 INFO reduce.MergeManagerImpl: Merging 1 files, 42 bytes from disk\n",
      "2024-12-19 11:57:42,889 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-12-19 11:57:42,889 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:42,891 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 28 bytes\n",
      "2024-12-19 11:57:42,891 INFO mapreduce.Job: Job job_local1255638818_0001 running in uber mode : false\n",
      "2024-12-19 11:57:42,891 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:42,892 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "2024-12-19 11:57:42,918 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-12-19 11:57:42,922 INFO mapred.Task: Task:attempt_local1255638818_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:42,924 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:42,924 INFO mapred.Task: Task attempt_local1255638818_0001_r_000000_0 is allowed to commit now\n",
      "2024-12-19 11:57:42,927 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1255638818_0001_r_000000_0' to file:/content/grep-temp-405868305\n",
      "2024-12-19 11:57:42,930 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-12-19 11:57:42,930 INFO mapred.Task: Task 'attempt_local1255638818_0001_r_000000_0' done.\n",
      "2024-12-19 11:57:42,932 INFO mapred.Task: Final Counters for attempt_local1255638818_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15807881\n",
      "\t\tFILE: Number of bytes written=920868\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=48\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=361758720\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=122\n",
      "2024-12-19 11:57:42,932 INFO mapred.LocalJobRunner: Finishing task: attempt_local1255638818_0001_r_000000_0\n",
      "2024-12-19 11:57:42,932 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-12-19 11:57:43,893 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-12-19 11:57:43,894 INFO mapreduce.Job: Job job_local1255638818_0001 completed successfully\n",
      "2024-12-19 11:57:43,922 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=46331897\n",
      "\t\tFILE: Number of bytes written=2762220\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10503\n",
      "\t\tMap output records=1828\n",
      "\t\tMap output bytes=29248\n",
      "\t\tMap output materialized bytes=48\n",
      "\t\tInput split bytes=186\n",
      "\t\tCombine input records=1828\n",
      "\t\tCombine output records=2\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=48\n",
      "\t\tReduce input records=2\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=4\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=39\n",
      "\t\tTotal committed heap usage (bytes)=1085276160\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=15525915\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=122\n",
      "2024-12-19 11:57:43,994 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:44,023 INFO input.FileInputFormat: Total input files to process : 1\n",
      "2024-12-19 11:57:44,033 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "2024-12-19 11:57:44,109 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local518477828_0002\n",
      "2024-12-19 11:57:44,109 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-12-19 11:57:44,381 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-12-19 11:57:44,381 INFO mapreduce.Job: Running job: job_local518477828_0002\n",
      "2024-12-19 11:57:44,382 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-12-19 11:57:44,382 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:44,382 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:44,382 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:44,383 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-12-19 11:57:44,393 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-12-19 11:57:44,393 INFO mapred.LocalJobRunner: Starting task: attempt_local518477828_0002_m_000000_0\n",
      "2024-12-19 11:57:44,401 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:44,401 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:44,401 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:44,402 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:44,406 INFO mapred.MapTask: Processing split: file:/content/grep-temp-405868305/part-r-00000:0+110\n",
      "2024-12-19 11:57:44,454 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:44,454 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:44,454 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:44,454 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:44,454 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:44,467 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:44,495 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:44,495 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:44,496 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:44,496 INFO mapred.MapTask: bufstart = 0; bufend = 16; bufvoid = 104857600\n",
      "2024-12-19 11:57:44,496 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600\n",
      "2024-12-19 11:57:44,497 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:44,504 INFO mapred.Task: Task:attempt_local518477828_0002_m_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:44,507 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:44,507 INFO mapred.Task: Task 'attempt_local518477828_0002_m_000000_0' done.\n",
      "2024-12-19 11:57:44,507 INFO mapred.Task: Final Counters for attempt_local518477828_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=16089516\n",
      "\t\tFILE: Number of bytes written=1837053\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=16\n",
      "\t\tMap output materialized bytes=24\n",
      "\t\tInput split bytes=111\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=27\n",
      "\t\tTotal committed heap usage (bytes)=361758720\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=122\n",
      "2024-12-19 11:57:44,507 INFO mapred.LocalJobRunner: Finishing task: attempt_local518477828_0002_m_000000_0\n",
      "2024-12-19 11:57:44,523 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-12-19 11:57:44,525 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-12-19 11:57:44,526 INFO mapred.LocalJobRunner: Starting task: attempt_local518477828_0002_r_000000_0\n",
      "2024-12-19 11:57:44,529 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:44,529 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:44,529 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:44,529 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:44,530 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ab383d7\n",
      "2024-12-19 11:57:44,535 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:44,538 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-12-19 11:57:44,539 INFO reduce.EventFetcher: attempt_local518477828_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-12-19 11:57:44,549 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local518477828_0002_m_000000_0 decomp: 20 len: 24 to MEMORY\n",
      "2024-12-19 11:57:44,550 INFO reduce.InMemoryMapOutput: Read 20 bytes from map-output for attempt_local518477828_0002_m_000000_0\n",
      "2024-12-19 11:57:44,553 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 20, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->20\n",
      "2024-12-19 11:57:44,557 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-12-19 11:57:44,557 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-12-19 11:57:44,558 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-12-19 11:57:44,559 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:44,562 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 10 bytes\n",
      "2024-12-19 11:57:44,565 INFO reduce.MergeManagerImpl: Merged 1 segments, 20 bytes to disk to satisfy reduce memory limit\n",
      "2024-12-19 11:57:44,566 INFO reduce.MergeManagerImpl: Merging 1 files, 24 bytes from disk\n",
      "2024-12-19 11:57:44,566 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-12-19 11:57:44,566 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:44,568 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 10 bytes\n",
      "2024-12-19 11:57:44,568 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-12-19 11:57:44,578 INFO mapred.Task: Task:attempt_local518477828_0002_r_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:44,582 INFO mapred.LocalJobRunner: 1 / 1 copied.\n",
      "2024-12-19 11:57:44,582 INFO mapred.Task: Task attempt_local518477828_0002_r_000000_0 is allowed to commit now\n",
      "2024-12-19 11:57:44,587 INFO output.FileOutputCommitter: Saved output of task 'attempt_local518477828_0002_r_000000_0' to file:/content/samsung\n",
      "2024-12-19 11:57:44,594 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-12-19 11:57:44,594 INFO mapred.Task: Task 'attempt_local518477828_0002_r_000000_0' done.\n",
      "2024-12-19 11:57:44,594 INFO mapred.Task: Final Counters for attempt_local518477828_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=16089596\n",
      "\t\tFILE: Number of bytes written=1837102\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=24\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=1\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=361758720\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=25\n",
      "2024-12-19 11:57:44,594 INFO mapred.LocalJobRunner: Finishing task: attempt_local518477828_0002_r_000000_0\n",
      "2024-12-19 11:57:44,594 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-12-19 11:57:45,381 INFO mapreduce.Job: Job job_local518477828_0002 running in uber mode : false\n",
      "2024-12-19 11:57:45,382 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-12-19 11:57:45,382 INFO mapreduce.Job: Job job_local518477828_0002 completed successfully\n",
      "2024-12-19 11:57:45,387 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=32179112\n",
      "\t\tFILE: Number of bytes written=3674155\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1\n",
      "\t\tMap output records=1\n",
      "\t\tMap output bytes=16\n",
      "\t\tMap output materialized bytes=24\n",
      "\t\tInput split bytes=111\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=24\n",
      "\t\tReduce input records=1\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=2\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=27\n",
      "\t\tTotal committed heap usage (bytes)=723517440\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=122\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=25\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar grep /dataset /content/samsung 'samsung'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1734609473793,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "DdGtAFGNa0ga",
    "outputId": "98785bd1-8123-4439-a551-67cbcd0aac8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw-r--r-- 1 root root 13 Dec 19 11:57 part-r-00000\n",
      "-rw-r--r-- 1 root root  0 Dec 19 11:57 _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls -l /content/samsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1734609474006,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "3S-d1VcJbAne",
    "outputId": "d4e4716d-b452-4ce9-ae3d-30e16cb0a88b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1828\tsamsung\n"
     ]
    }
   ],
   "source": [
    "!cat ./samsung/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKzt26lS6WVy"
   },
   "source": [
    "Vemos que la palabra apple aparece 322 veces y la palabra samsung aparece 1828 veces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6VeXqFFEEKH"
   },
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D3u0p2z5EFCv"
   },
   "source": [
    "Podemos ver que aunque son las 2 marcas más conocidas por todos, samsung necesita diseñar y poner en el mercado 5 veces mas modelos distintos de móviles para poder competir con Apple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWTwdQrMcraT"
   },
   "source": [
    "# MarReduce en Java"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YigVC8Pipy2"
   },
   "source": [
    "Generamos el código .java"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734609474007,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "tbSXFH30Sfs4",
    "outputId": "91c846de-c61a-4cb4-bfe6-f61dea3d5b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wordcount_mapreduce.java\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a wordcount_mapreduce.java\n",
    "\n",
    "import java.io.IOException;\n",
    "import java.util.regex.Matcher;\n",
    "import java.util.regex.Pattern;\n",
    "import org.apache.hadoop.conf.Configuration;\n",
    "import org.apache.hadoop.fs.Path;\n",
    "import org.apache.hadoop.io.IntWritable;\n",
    "import org.apache.hadoop.io.Text;\n",
    "import org.apache.hadoop.mapreduce.Job;\n",
    "import org.apache.hadoop.mapreduce.Mapper;\n",
    "import org.apache.hadoop.mapreduce.Reducer;\n",
    "import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;\n",
    "import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;\n",
    "\n",
    "public class wordcount_mapreduce {\n",
    "\n",
    "    public static class WordCountMapper extends Mapper<Object, Text, Text, IntWritable> {\n",
    "\n",
    "        private Text wordToCount = new Text();\n",
    "        private final static IntWritable one = new IntWritable(1);\n",
    "\n",
    "        // Expresión regular para buscar la palabra objetivo\n",
    "        private Pattern targetPattern;\n",
    "\n",
    "        @Override\n",
    "        protected void setup(Context context) throws IOException, InterruptedException {\n",
    "            // Obtenemos la palabra a buscar del contexto\n",
    "            Configuration conf = context.getConfiguration();\n",
    "            String targetWord = conf.get(\"targetWord\").toLowerCase();\n",
    "\n",
    "            // Creamos un patrón que busca la palabra completa (\\b asegura límites de palabra)\n",
    "            targetPattern = Pattern.compile(\"\\\\b\" + Pattern.quote(targetWord) + \"\\\\b\", Pattern.CASE_INSENSITIVE);\n",
    "        }\n",
    "\n",
    "        @Override\n",
    "        public void map(Object key, Text value, Context context) throws IOException, InterruptedException {\n",
    "            // Obtener el nombre del archivo actual\n",
    "            String filename = ((org.apache.hadoop.mapreduce.lib.input.FileSplit) context.getInputSplit()).getPath().getName();\n",
    "\n",
    "            // Convertimos la línea a minúsculas\n",
    "            String line = value.toString().toLowerCase();\n",
    "\n",
    "            // Usamos el patrón para buscar coincidencias en la línea\n",
    "            Matcher matcher = targetPattern.matcher(line);\n",
    "            while (matcher.find()) {\n",
    "                // Si encontramos la palabra, emitimos (archivo_nombre : palabra, 1)\n",
    "                wordToCount.set(filename + \" : \" + matcher.group());\n",
    "                context.write(wordToCount, one);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {\n",
    "\n",
    "        private IntWritable result = new IntWritable();\n",
    "\n",
    "        @Override\n",
    "        public void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {\n",
    "            int sum = 0;\n",
    "\n",
    "            // Sumamos todas las ocurrencias de la palabra\n",
    "            for (IntWritable val : values) {\n",
    "                sum += val.get();\n",
    "            }\n",
    "\n",
    "            result.set(sum);\n",
    "            context.write(key, result);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public static void main(String[] args) throws Exception {\n",
    "        if (args.length < 3) {\n",
    "            System.err.println(\"Usage: WordCountMapReduce <input_path> <output_path> <word_to_count>\");\n",
    "            System.exit(-1);\n",
    "        }\n",
    "\n",
    "        Configuration conf = new Configuration();\n",
    "        conf.set(\"targetWord\", args[2]); // Pasamos la palabra objetivo como parámetro\n",
    "\n",
    "        Job job = Job.getInstance(conf, \"Word Count for Specific Word\");\n",
    "        job.setJarByClass(wordcount_mapreduce.class);\n",
    "        job.setMapperClass(WordCountMapper.class);\n",
    "        // Elimina la línea que asigna el Combiner\n",
    "        job.setReducerClass(WordCountReducer.class);\n",
    "        job.setOutputKeyClass(Text.class);\n",
    "        job.setOutputValueClass(IntWritable.class);\n",
    "\n",
    "        FileInputFormat.addInputPath(job, new Path(args[0]));\n",
    "        FileOutputFormat.setOutputPath(job, new Path(args[1]));\n",
    "\n",
    "        System.exit(job.waitForCompletion(true) ? 0 : 1);\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFtmD2LuG-FA"
   },
   "source": [
    "Compilamos el archivo .java para generar .jar y poder ejecutarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2596,
     "status": "ok",
     "timestamp": 1734609476600,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "TPouKM3VHDB5",
    "outputId": "d790b655-186c-4859-827a-3f266b0de46e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added manifest\n",
      "adding: wordcount_mapreduce$WordCountMapper.class(in = 3311) (out= 1353)(deflated 59%)\n",
      "adding: wordcount_mapreduce$WordCountReducer.class(in = 1791) (out= 754)(deflated 57%)\n",
      "adding: wordcount_mapreduce.class(in = 1813) (out= 971)(deflated 46%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: [path] bad path element \"/usr/local/hadoop-3.3.6/share/hadoop/common/lib/jaxb-api.jar\": no such file or directory\n",
      "warning: [path] bad path element \"/usr/local/hadoop-3.3.6/share/hadoop/common/lib/activation.jar\": no such file or directory\n",
      "warning: [path] bad path element \"/usr/local/hadoop-3.3.6/share/hadoop/common/lib/jsr173_1.0_api.jar\": no such file or directory\n",
      "warning: [path] bad path element \"/usr/local/hadoop-3.3.6/share/hadoop/common/lib/jaxb1-impl.jar\": no such file or directory\n",
      "4 warnings\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "javac -cp \"/usr/local/hadoop-3.3.6/share/hadoop/common/*:/usr/local/hadoop-3.3.6/share/hadoop/mapreduce/*:/usr/local/hadoop-3.3.6/share/hadoop/common/lib/*\" wordcount_mapreduce.java -Xlint\n",
    "jar -cvf wordcountmapreduce.jar *.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5256,
     "status": "ok",
     "timestamp": 1734609481854,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "yXIMkglEXysj",
    "outputId": "e84c99c0-353c-42f1-9af7-8aac68fec029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:57:50,287 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2024-12-19 11:57:50,496 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-12-19 11:57:50,496 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2024-12-19 11:57:50,634 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.\n",
      "2024-12-19 11:57:50,786 INFO input.FileInputFormat: Total input files to process : 2\n",
      "2024-12-19 11:57:50,832 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2024-12-19 11:57:51,180 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local976075796_0001\n",
      "2024-12-19 11:57:51,180 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-12-19 11:57:51,461 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-12-19 11:57:51,462 INFO mapreduce.Job: Running job: job_local976075796_0001\n",
      "2024-12-19 11:57:51,473 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-12-19 11:57:51,482 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:51,484 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:51,484 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:51,487 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\n",
      "2024-12-19 11:57:51,571 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-12-19 11:57:51,573 INFO mapred.LocalJobRunner: Starting task: attempt_local976075796_0001_m_000000_0\n",
      "2024-12-19 11:57:51,616 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:51,616 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:51,616 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:51,655 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:51,663 INFO mapred.MapTask: Processing split: file:/dataset/data.json:0+14322766\n",
      "2024-12-19 11:57:51,765 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:51,765 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:51,765 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:51,765 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:51,765 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:51,769 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:52,469 INFO mapreduce.Job: Job job_local976075796_0001 running in uber mode : false\n",
      "2024-12-19 11:57:52,470 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2024-12-19 11:57:52,645 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:52,646 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:52,646 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:52,646 INFO mapred.MapTask: bufstart = 0; bufend = 9966; bufvoid = 104857600\n",
      "2024-12-19 11:57:52,646 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26212588(104850352); length = 1809/6553600\n",
      "2024-12-19 11:57:52,658 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:52,674 INFO mapred.Task: Task:attempt_local976075796_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:52,679 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:52,679 INFO mapred.Task: Task 'attempt_local976075796_0001_m_000000_0' done.\n",
      "2024-12-19 11:57:52,690 INFO mapred.Task: Final Counters for attempt_local976075796_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=14438839\n",
      "\t\tFILE: Number of bytes written=647339\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=8794\n",
      "\t\tMap output records=453\n",
      "\t\tMap output bytes=9966\n",
      "\t\tMap output materialized bytes=10878\n",
      "\t\tInput split bytes=88\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=453\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=17\n",
      "\t\tTotal committed heap usage (bytes)=402653184\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=14434682\n",
      "2024-12-19 11:57:52,690 INFO mapred.LocalJobRunner: Finishing task: attempt_local976075796_0001_m_000000_0\n",
      "2024-12-19 11:57:52,691 INFO mapred.LocalJobRunner: Starting task: attempt_local976075796_0001_m_000001_0\n",
      "2024-12-19 11:57:52,693 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:52,693 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:52,693 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:52,693 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:52,696 INFO mapred.MapTask: Processing split: file:/dataset/processed_data2.csv:0+1082761\n",
      "2024-12-19 11:57:52,725 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:57:52,725 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:57:52,725 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:57:52,725 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:57:52,725 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:57:52,745 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:57:52,861 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:57:52,863 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:57:52,863 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:57:52,863 INFO mapred.MapTask: bufstart = 0; bufend = 37248; bufvoid = 104857600\n",
      "2024-12-19 11:57:52,863 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26209744(104838976); length = 4653/6553600\n",
      "2024-12-19 11:57:52,872 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:57:52,875 INFO mapred.Task: Task:attempt_local976075796_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:52,879 INFO mapred.LocalJobRunner: map\n",
      "2024-12-19 11:57:52,880 INFO mapred.Task: Task 'attempt_local976075796_0001_m_000001_0' done.\n",
      "2024-12-19 11:57:52,880 INFO mapred.Task: Final Counters for attempt_local976075796_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15530277\n",
      "\t\tFILE: Number of bytes written=686953\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1709\n",
      "\t\tMap output records=1164\n",
      "\t\tMap output bytes=37248\n",
      "\t\tMap output materialized bytes=39582\n",
      "\t\tInput split bytes=98\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=1164\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=9\n",
      "\t\tTotal committed heap usage (bytes)=402653184\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1091233\n",
      "2024-12-19 11:57:52,880 INFO mapred.LocalJobRunner: Finishing task: attempt_local976075796_0001_m_000001_0\n",
      "2024-12-19 11:57:52,881 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-12-19 11:57:52,886 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-12-19 11:57:52,888 INFO mapred.LocalJobRunner: Starting task: attempt_local976075796_0001_r_000000_0\n",
      "2024-12-19 11:57:52,901 INFO output.PathOutputCommitterFactory: No output committer factory defined, defaulting to FileOutputCommitterFactory\n",
      "2024-12-19 11:57:52,901 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:57:52,901 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:57:52,902 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:57:52,913 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59b4c377\n",
      "2024-12-19 11:57:52,915 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:57:52,963 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-12-19 11:57:52,969 INFO reduce.EventFetcher: attempt_local976075796_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-12-19 11:57:53,034 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local976075796_0001_m_000001_0 decomp: 39578 len: 39582 to MEMORY\n",
      "2024-12-19 11:57:53,039 INFO reduce.InMemoryMapOutput: Read 39578 bytes from map-output for attempt_local976075796_0001_m_000001_0\n",
      "2024-12-19 11:57:53,042 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 39578, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->39578\n",
      "2024-12-19 11:57:53,049 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local976075796_0001_m_000000_0 decomp: 10874 len: 10878 to MEMORY\n",
      "2024-12-19 11:57:53,050 INFO reduce.InMemoryMapOutput: Read 10874 bytes from map-output for attempt_local976075796_0001_m_000000_0\n",
      "2024-12-19 11:57:53,050 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 10874, inMemoryMapOutputs.size() -> 2, commitMemory -> 39578, usedMemory ->50452\n",
      "2024-12-19 11:57:53,051 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-12-19 11:57:53,052 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:53,053 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-12-19 11:57:53,066 INFO mapred.Merger: Merging 2 sorted segments\n",
      "2024-12-19 11:57:53,067 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 50402 bytes\n",
      "2024-12-19 11:57:53,088 INFO reduce.MergeManagerImpl: Merged 2 segments, 50452 bytes to disk to satisfy reduce memory limit\n",
      "2024-12-19 11:57:53,089 INFO reduce.MergeManagerImpl: Merging 1 files, 50454 bytes from disk\n",
      "2024-12-19 11:57:53,090 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-12-19 11:57:53,090 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:57:53,092 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 50430 bytes\n",
      "2024-12-19 11:57:53,093 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:53,104 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-12-19 11:57:53,148 INFO mapred.Task: Task:attempt_local976075796_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:57:53,151 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:57:53,152 INFO mapred.Task: Task attempt_local976075796_0001_r_000000_0 is allowed to commit now\n",
      "2024-12-19 11:57:53,157 INFO output.FileOutputCommitter: Saved output of task 'attempt_local976075796_0001_r_000000_0' to file:/output_apple\n",
      "2024-12-19 11:57:53,158 INFO mapred.LocalJobRunner: reduce > reduce\n",
      "2024-12-19 11:57:53,158 INFO mapred.Task: Task 'attempt_local976075796_0001_r_000000_0' done.\n",
      "2024-12-19 11:57:53,159 INFO mapred.Task: Final Counters for attempt_local976075796_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15631255\n",
      "\t\tFILE: Number of bytes written=737474\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=50460\n",
      "\t\tReduce input records=1617\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=1617\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=402653184\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=67\n",
      "2024-12-19 11:57:53,159 INFO mapred.LocalJobRunner: Finishing task: attempt_local976075796_0001_r_000000_0\n",
      "2024-12-19 11:57:53,159 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-12-19 11:57:53,475 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-12-19 11:57:53,475 INFO mapreduce.Job: Job job_local976075796_0001 completed successfully\n",
      "2024-12-19 11:57:53,488 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=45600371\n",
      "\t\tFILE: Number of bytes written=2071766\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10503\n",
      "\t\tMap output records=1617\n",
      "\t\tMap output bytes=47214\n",
      "\t\tMap output materialized bytes=50460\n",
      "\t\tInput split bytes=186\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=50460\n",
      "\t\tReduce input records=1617\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=3234\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=26\n",
      "\t\tTotal committed heap usage (bytes)=1207959552\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=15525915\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=67\n"
     ]
    }
   ],
   "source": [
    "!hadoop jar wordcountmapreduce.jar wordcount_mapreduce /dataset /output_apple apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2045,
     "status": "ok",
     "timestamp": 1734609483896,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "ceAOGXljZctV",
    "outputId": "9f5a4ae4-57e7-418e-f29c-d4ba837364a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root root   14322766 2024-12-19 11:57 /dataset/data.json\n",
      "-rw-r--r--   1 root root    1082761 2024-12-19 11:57 /dataset/processed_data2.csv\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3304,
     "status": "ok",
     "timestamp": 1734609487198,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "3PD_ke6Ocn3R",
    "outputId": "1c038d26-9cb0-4cf3-9b96-45a11038c727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.json : apple\t453\n",
      "processed_data2.csv : apple\t1164\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -cat /output_apple/part*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RJ6lT_BHdX17"
   },
   "source": [
    "# MapReduce Python con Hadoop-Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1734609487596,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "-wpWaFCJiwMO",
    "outputId": "6a7af289-d8b1-413b-f30a-bbba5fd97da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'output_python': No such file or directory\n",
      "rm: cannot remove 'map_word_in_file.py': No such file or directory\n",
      "rm: cannot remove 'reducer_word_in_file.py': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm -r output_python\n",
    "!rm -r map_word_in_file.py\n",
    "!rm -r reducer_word_in_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTb4OBfSd5L6"
   },
   "source": [
    "Creamos el archivo para el map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1734609487597,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "sJy5Ndcddd1l",
    "outputId": "c0acacf1-3ec3-43ae-b41c-c34b1f0d42fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing map_word_in_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a map_word_in_file.py\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "\n",
    "# La palabra a buscar se pasa como argumento\n",
    "target_word = sys.argv[1].lower()\n",
    "\n",
    "# Leer líneas de la entrada estándar\n",
    "for line in sys.stdin:\n",
    "    # Obtener el nombre del fichero desde las variables de entorno de Hadoop\n",
    "    filename = os.environ.get('map_input_file', 'unknown_file')\n",
    "\n",
    "    # Limpiar y normalizar la línea\n",
    "    line = line.strip().lower()\n",
    "\n",
    "    # Usar una expresión regular para encontrar coincidencias exactas de palabras\n",
    "    pattern = r'\\b{}\\b'.format(re.escape(target_word))  # \\b asegura coincidencias completas\n",
    "    matches = re.findall(pattern, line)\n",
    "\n",
    "    # Si hay coincidencias, contar y emitir\n",
    "    if matches:\n",
    "        count = len(matches)\n",
    "        print(f\"{filename}\\t{count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RborgcRgd8GB"
   },
   "source": [
    "Creamos el archivo para el reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1734609487597,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "rplCk7tJdwcI",
    "outputId": "8d5b91a3-4659-4d2a-951d-6bd0ed51f790"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing reducer_word_in_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a reducer_word_in_file.py\n",
    "\n",
    "import sys\n",
    "\n",
    "current_file = None\n",
    "current_count = 0\n",
    "\n",
    "import sys\n",
    "\n",
    "current_file = None\n",
    "current_count = 0\n",
    "\n",
    "# Leer líneas de la entrada estándar\n",
    "for line in sys.stdin:\n",
    "    # Dividir la entrada en filename y count\n",
    "    filename, count = line.strip().split('\\t', 1)\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "    # Acumular el conteo para cada archivo\n",
    "    if current_file == filename:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_file:\n",
    "            # Emitir el resultado para el archivo anterior\n",
    "            print(f\"{current_file}\\t{current_count}\")\n",
    "        # Reiniciar el acumulador para el nuevo archivo\n",
    "        current_file = filename\n",
    "        current_count = count\n",
    "\n",
    "# Emitir el resultado del último archivo\n",
    "if current_file:\n",
    "    print(f\"{current_file}\\t{current_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLwYcbLGfIcV"
   },
   "source": [
    "Damos permisos a los archivos creados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1734609487899,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "rZvc5w_BfKr-",
    "outputId": "d5073f6c-6980-44c3-fe4e-e8e61d3163fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16456\n",
      "drwxr-xr-x 1 root root     4096 Dec 19 11:57  .\n",
      "drwxr-xr-x 1 root root     4096 Dec 19 11:57  ..\n",
      "drwxr-xr-x 4 root root     4096 Dec 17 14:21  .config\n",
      "-rw-r--r-- 1 root root 14322766 Oct 28 16:48  data.json\n",
      "drwxr-xr-x 2 root root     4096 Dec 19 11:57  grep_apple\n",
      "-rwxr-xr-x 1 root root      731 Dec 19 11:57  map_word_in_file.py\n",
      "-rw-r--r-- 1 root root  1082761 Oct 28 16:48  processed_data2.csv\n",
      "-rwxr-xr-x 1 root root      816 Dec 19 11:57  reducer_word_in_file.py\n",
      "drwxr-xr-x 1 root root     4096 Dec 17 14:21  sample_data\n",
      "drwxr-xr-x 2 root root     4096 Dec 19 11:57  samsung\n",
      "-rw-r--r-- 1 root root  1385178 Dec 19 11:56  telefonos-2024.zip\n",
      "-rw-r--r-- 1 root root     3311 Dec 19 11:57 'wordcount_mapreduce$WordCountMapper.class'\n",
      "-rw-r--r-- 1 root root     1791 Dec 19 11:57 'wordcount_mapreduce$WordCountReducer.class'\n",
      "-rw-r--r-- 1 root root     1813 Dec 19 11:57  wordcount_mapreduce.class\n",
      "-rw-r--r-- 1 root root     3898 Dec 19 11:57  wordcountmapreduce.jar\n",
      "-rw-r--r-- 1 root root     3696 Dec 19 11:57  wordcount_mapreduce.java\n"
     ]
    }
   ],
   "source": [
    "!chmod +x map_word_in_file.py reducer_word_in_file.py\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6ZD5DuYfRV7"
   },
   "source": [
    "Ejecutamos el map y el reducer utilizando Hadoop-Sreaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5576,
     "status": "ok",
     "timestamp": 1734609493473,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "Ozllw22NfRof",
    "outputId": "66a8c1da-eea0-4ea7-e620-60f0e04fea70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "packageJobJar: [map_word_in_file.py, reducer_word_in_file.py] [] /tmp/streamjob14994178510656868071.jar tmpDir=null\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 11:58:00,868 WARN streaming.StreamJob: -file option is deprecated, please use generic option -files instead.\n",
      "2024-12-19 11:58:01,610 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\n",
      "2024-12-19 11:58:01,783 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\n",
      "2024-12-19 11:58:01,783 INFO impl.MetricsSystemImpl: JobTracker metrics system started\n",
      "2024-12-19 11:58:01,807 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:58:02,063 INFO mapred.FileInputFormat: Total input files to process : 2\n",
      "2024-12-19 11:58:02,090 INFO mapreduce.JobSubmitter: number of splits:2\n",
      "2024-12-19 11:58:02,409 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1340815619_0001\n",
      "2024-12-19 11:58:02,409 INFO mapreduce.JobSubmitter: Executing with tokens: []\n",
      "2024-12-19 11:58:02,871 INFO mapred.LocalDistributedCacheManager: Localized file:/content/map_word_in_file.py as file:/tmp/hadoop-root/mapred/local/job_local1340815619_0001_8940f054-a624-4650-9567-413123b6c7b3/map_word_in_file.py\n",
      "2024-12-19 11:58:02,901 INFO mapred.LocalDistributedCacheManager: Localized file:/content/reducer_word_in_file.py as file:/tmp/hadoop-root/mapred/local/job_local1340815619_0001_fe94ae77-b8e4-4162-b837-c14e3f1feb34/reducer_word_in_file.py\n",
      "2024-12-19 11:58:03,027 INFO mapreduce.Job: The url to track the job: http://localhost:8080/\n",
      "2024-12-19 11:58:03,028 INFO mapreduce.Job: Running job: job_local1340815619_0001\n",
      "2024-12-19 11:58:03,035 INFO mapred.LocalJobRunner: OutputCommitter set in config null\n",
      "2024-12-19 11:58:03,037 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapred.FileOutputCommitter\n",
      "2024-12-19 11:58:03,043 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:58:03,043 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:58:03,093 INFO mapred.LocalJobRunner: Waiting for map tasks\n",
      "2024-12-19 11:58:03,098 INFO mapred.LocalJobRunner: Starting task: attempt_local1340815619_0001_m_000000_0\n",
      "2024-12-19 11:58:03,130 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:58:03,133 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:58:03,162 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:58:03,177 INFO mapred.MapTask: Processing split: file:/dataset/data.json:0+14322766\n",
      "2024-12-19 11:58:03,193 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2024-12-19 11:58:03,266 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:58:03,266 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:58:03,266 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:58:03,266 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:58:03,266 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:58:03,270 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:58:03,277 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, map_word_in_file.py, apple]\n",
      "2024-12-19 11:58:03,285 INFO Configuration.deprecation: mapred.work.output.dir is deprecated. Instead, use mapreduce.task.output.dir\n",
      "2024-12-19 11:58:03,289 INFO Configuration.deprecation: mapred.local.dir is deprecated. Instead, use mapreduce.cluster.local.dir\n",
      "2024-12-19 11:58:03,289 INFO Configuration.deprecation: map.input.file is deprecated. Instead, use mapreduce.map.input.file\n",
      "2024-12-19 11:58:03,289 INFO Configuration.deprecation: map.input.length is deprecated. Instead, use mapreduce.map.input.length\n",
      "2024-12-19 11:58:03,290 INFO Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id\n",
      "2024-12-19 11:58:03,290 INFO Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition\n",
      "2024-12-19 11:58:03,292 INFO Configuration.deprecation: map.input.start is deprecated. Instead, use mapreduce.map.input.start\n",
      "2024-12-19 11:58:03,292 INFO Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap\n",
      "2024-12-19 11:58:03,292 INFO Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2024-12-19 11:58:03,293 INFO Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id\n",
      "2024-12-19 11:58:03,293 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2024-12-19 11:58:03,294 INFO Configuration.deprecation: user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-12-19 11:58:03,330 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:03,331 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:03,391 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:03,482 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,034 INFO mapreduce.Job: Job job_local1340815619_0001 running in uber mode : false\n",
      "2024-12-19 11:58:04,035 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "2024-12-19 11:58:04,192 INFO streaming.PipeMapRed: Records R/W=8794/1\n",
      "2024-12-19 11:58:04,210 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2024-12-19 11:58:04,211 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2024-12-19 11:58:04,219 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:58:04,219 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:58:04,220 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:58:04,220 INFO mapred.MapTask: bufstart = 0; bufend = 3770; bufvoid = 104857600\n",
      "2024-12-19 11:58:04,220 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213820(104855280); length = 577/6553600\n",
      "2024-12-19 11:58:04,238 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:58:04,262 INFO mapred.Task: Task:attempt_local1340815619_0001_m_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:58:04,266 INFO mapred.LocalJobRunner: Records R/W=8794/1\n",
      "2024-12-19 11:58:04,266 INFO mapred.Task: Task 'attempt_local1340815619_0001_m_000000_0' done.\n",
      "2024-12-19 11:58:04,275 INFO mapred.Task: Final Counters for attempt_local1340815619_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=14437522\n",
      "\t\tFILE: Number of bytes written=650298\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=8794\n",
      "\t\tMap output records=145\n",
      "\t\tMap output bytes=3770\n",
      "\t\tMap output materialized bytes=4066\n",
      "\t\tInput split bytes=75\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=145\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=354418688\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=14434682\n",
      "2024-12-19 11:58:04,275 INFO mapred.LocalJobRunner: Finishing task: attempt_local1340815619_0001_m_000000_0\n",
      "2024-12-19 11:58:04,276 INFO mapred.LocalJobRunner: Starting task: attempt_local1340815619_0001_m_000001_0\n",
      "2024-12-19 11:58:04,280 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:58:04,280 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:58:04,280 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:58:04,284 INFO mapred.MapTask: Processing split: file:/dataset/processed_data2.csv:0+1082761\n",
      "2024-12-19 11:58:04,288 INFO mapred.MapTask: numReduceTasks: 1\n",
      "2024-12-19 11:58:04,325 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2024-12-19 11:58:04,325 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100\n",
      "2024-12-19 11:58:04,325 INFO mapred.MapTask: soft limit at 83886080\n",
      "2024-12-19 11:58:04,325 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600\n",
      "2024-12-19 11:58:04,325 INFO mapred.MapTask: kvstart = 26214396; length = 6553600\n",
      "2024-12-19 11:58:04,333 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2024-12-19 11:58:04,358 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, map_word_in_file.py, apple]\n",
      "2024-12-19 11:58:04,406 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,406 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,408 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,517 INFO streaming.PipeMapRed: R/W/S=1000/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,571 INFO streaming.PipeMapRed: Records R/W=1709/1\n",
      "2024-12-19 11:58:04,579 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2024-12-19 11:58:04,580 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2024-12-19 11:58:04,581 INFO mapred.LocalJobRunner: \n",
      "2024-12-19 11:58:04,581 INFO mapred.MapTask: Starting flush of map output\n",
      "2024-12-19 11:58:04,581 INFO mapred.MapTask: Spilling map output\n",
      "2024-12-19 11:58:04,581 INFO mapred.MapTask: bufstart = 0; bufend = 6984; bufvoid = 104857600\n",
      "2024-12-19 11:58:04,581 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26213624(104854496); length = 773/6553600\n",
      "2024-12-19 11:58:04,584 INFO mapred.MapTask: Finished spill 0\n",
      "2024-12-19 11:58:04,594 INFO mapred.Task: Task:attempt_local1340815619_0001_m_000001_0 is done. And is in the process of committing\n",
      "2024-12-19 11:58:04,597 INFO mapred.LocalJobRunner: Records R/W=1709/1\n",
      "2024-12-19 11:58:04,598 INFO mapred.Task: Task 'attempt_local1340815619_0001_m_000001_0' done.\n",
      "2024-12-19 11:58:04,599 INFO mapred.Task: Final Counters for attempt_local1340815619_0001_m_000001_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15528934\n",
      "\t\tFILE: Number of bytes written=657708\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=1709\n",
      "\t\tMap output records=194\n",
      "\t\tMap output bytes=6984\n",
      "\t\tMap output materialized bytes=7378\n",
      "\t\tInput split bytes=85\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=194\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=20\n",
      "\t\tTotal committed heap usage (bytes)=354418688\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=1091233\n",
      "2024-12-19 11:58:04,599 INFO mapred.LocalJobRunner: Finishing task: attempt_local1340815619_0001_m_000001_0\n",
      "2024-12-19 11:58:04,600 INFO mapred.LocalJobRunner: map task executor complete.\n",
      "2024-12-19 11:58:04,604 INFO mapred.LocalJobRunner: Waiting for reduce tasks\n",
      "2024-12-19 11:58:04,604 INFO mapred.LocalJobRunner: Starting task: attempt_local1340815619_0001_r_000000_0\n",
      "2024-12-19 11:58:04,619 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\n",
      "2024-12-19 11:58:04,619 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2024-12-19 11:58:04,619 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]\n",
      "2024-12-19 11:58:04,629 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4ae0ed89\n",
      "2024-12-19 11:58:04,632 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!\n",
      "2024-12-19 11:58:04,664 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=2382574336, maxSingleShuffleLimit=595643584, mergeThreshold=1572499072, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2024-12-19 11:58:04,677 INFO reduce.EventFetcher: attempt_local1340815619_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2024-12-19 11:58:04,730 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1340815619_0001_m_000000_0 decomp: 4062 len: 4066 to MEMORY\n",
      "2024-12-19 11:58:04,734 INFO reduce.InMemoryMapOutput: Read 4062 bytes from map-output for attempt_local1340815619_0001_m_000000_0\n",
      "2024-12-19 11:58:04,739 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 4062, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->4062\n",
      "2024-12-19 11:58:04,748 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local1340815619_0001_m_000001_0 decomp: 7374 len: 7378 to MEMORY\n",
      "2024-12-19 11:58:04,749 INFO reduce.InMemoryMapOutput: Read 7374 bytes from map-output for attempt_local1340815619_0001_m_000001_0\n",
      "2024-12-19 11:58:04,750 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 7374, inMemoryMapOutputs.size() -> 2, commitMemory -> 4062, usedMemory ->11436\n",
      "2024-12-19 11:58:04,754 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning\n",
      "2024-12-19 11:58:04,755 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:58:04,756 INFO reduce.MergeManagerImpl: finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2024-12-19 11:58:04,764 INFO mapred.Merger: Merging 2 sorted segments\n",
      "2024-12-19 11:58:04,764 INFO mapred.Merger: Down to the last merge-pass, with 2 segments left of total size: 11374 bytes\n",
      "2024-12-19 11:58:04,773 INFO reduce.MergeManagerImpl: Merged 2 segments, 11436 bytes to disk to satisfy reduce memory limit\n",
      "2024-12-19 11:58:04,774 INFO reduce.MergeManagerImpl: Merging 1 files, 11438 bytes from disk\n",
      "2024-12-19 11:58:04,775 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce\n",
      "2024-12-19 11:58:04,776 INFO mapred.Merger: Merging 1 sorted segments\n",
      "2024-12-19 11:58:04,777 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 11408 bytes\n",
      "2024-12-19 11:58:04,777 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:58:04,787 INFO streaming.PipeMapRed: PipeMapRed exec [/usr/local/bin/python, reducer_word_in_file.py]\n",
      "2024-12-19 11:58:04,791 INFO Configuration.deprecation: mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-12-19 11:58:04,794 INFO Configuration.deprecation: mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2024-12-19 11:58:04,820 INFO streaming.PipeMapRed: R/W/S=1/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,820 INFO streaming.PipeMapRed: R/W/S=10/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,822 INFO streaming.PipeMapRed: R/W/S=100/0/0 in:NA [rec/s] out:NA [rec/s]\n",
      "2024-12-19 11:58:04,893 INFO streaming.PipeMapRed: Records R/W=339/1\n",
      "2024-12-19 11:58:04,897 INFO streaming.PipeMapRed: MRErrorThread done\n",
      "2024-12-19 11:58:04,897 INFO streaming.PipeMapRed: mapRedFinished\n",
      "2024-12-19 11:58:04,899 INFO mapred.Task: Task:attempt_local1340815619_0001_r_000000_0 is done. And is in the process of committing\n",
      "2024-12-19 11:58:04,900 INFO mapred.LocalJobRunner: 2 / 2 copied.\n",
      "2024-12-19 11:58:04,900 INFO mapred.Task: Task attempt_local1340815619_0001_r_000000_0 is allowed to commit now\n",
      "2024-12-19 11:58:04,902 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1340815619_0001_r_000000_0' to file:/content/output_python\n",
      "2024-12-19 11:58:04,905 INFO mapred.LocalJobRunner: Records R/W=339/1 > reduce\n",
      "2024-12-19 11:58:04,905 INFO mapred.Task: Task 'attempt_local1340815619_0001_r_000000_0' done.\n",
      "2024-12-19 11:58:04,906 INFO mapred.Task: Final Counters for attempt_local1340815619_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=15551880\n",
      "\t\tFILE: Number of bytes written=669225\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=11444\n",
      "\t\tReduce input records=339\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=339\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=354418688\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=79\n",
      "2024-12-19 11:58:04,906 INFO mapred.LocalJobRunner: Finishing task: attempt_local1340815619_0001_r_000000_0\n",
      "2024-12-19 11:58:04,906 INFO mapred.LocalJobRunner: reduce task executor complete.\n",
      "2024-12-19 11:58:05,038 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "2024-12-19 11:58:05,039 INFO mapreduce.Job: Job job_local1340815619_0001 completed successfully\n",
      "2024-12-19 11:58:05,061 INFO mapreduce.Job: Counters: 30\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=45518336\n",
      "\t\tFILE: Number of bytes written=1977231\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10503\n",
      "\t\tMap output records=339\n",
      "\t\tMap output bytes=10754\n",
      "\t\tMap output materialized bytes=11444\n",
      "\t\tInput split bytes=160\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=2\n",
      "\t\tReduce shuffle bytes=11444\n",
      "\t\tReduce input records=339\n",
      "\t\tReduce output records=2\n",
      "\t\tSpilled Records=678\n",
      "\t\tShuffled Maps =2\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=2\n",
      "\t\tGC time elapsed (ms)=20\n",
      "\t\tTotal committed heap usage (bytes)=1063256064\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=15525915\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=79\n",
      "2024-12-19 11:58:05,062 INFO streaming.StreamJob: Output directory: output_python\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hadoop jar /usr/local/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar \\\n",
    "   -input /dataset \\\n",
    "   -output output_python \\\n",
    "   -file map_word_in_file.py  -file reducer_word_in_file.py  \\\n",
    "   -mapper 'python map_word_in_file.py apple'  -reducer 'python reducer_word_in_file.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twErp7mifrRI"
   },
   "source": [
    "Comprobamos los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1734609493473,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "kg0tTwL-occ9",
    "outputId": "6efbcc05-68f8-4238-ea88-93582fc9051b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\n",
      "-rw-r--r-- 1 root root 67 Dec 19 11:58 part-00000\n",
      "-rw-r--r-- 1 root root  0 Dec 19 11:58 _SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!ls -l output_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1734609493806,
     "user": {
      "displayName": "manuel arjona paniagua",
      "userId": "08402870124817110000"
     },
     "user_tz": -60
    },
    "id": "JaxrBBYuhV42",
    "outputId": "28a16347-08a7-4212-e125-3d6e223cbffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file:/dataset/data.json\t453\n",
      "file:/dataset/processed_data2.csv\t1164\n"
     ]
    }
   ],
   "source": [
    "!cat ./output_python/part-00000"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM+6HBJLgj5POQWWuDn4sHD",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
